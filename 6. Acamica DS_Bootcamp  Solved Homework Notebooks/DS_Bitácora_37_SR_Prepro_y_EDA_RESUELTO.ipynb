{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistemas de Recomendación - Netflix Prize Challenge\n",
    "\n",
    "Vamos a implementar un sistema de recomendación a través de un filtro colaborativo. Como son varios los pasos que debemos dar, está dividido en dos notebooks. Uno orientado al preprocesamiento y exploración de datos, y otro a la implementación de las técnicas que vimos.\n",
    "\n",
    "Algunas referencias útiles, además de las mencionadas en la presentación:\n",
    "* https://www.kaggle.com/ibtesama/getting-started-with-a-movie-recommendation-system\n",
    "* https://www.kaggle.com/gspmoreira/recommender-systems-in-python-101\n",
    "\n",
    "El dataset puede ser descargado [acá](https://www.kaggle.com/netflix-inc/netflix-prize-data)\n",
    "\n",
    "Importante leer el archivo `README.md` para la descripción de los archivos.\n",
    "\n",
    "## Grandes Volúmenes de Datos\n",
    "\n",
    "Uno de los desafíos que plantea este dataset es que es bastante \"grande\". Esto quiere decir que, si lo cargamos completo, ocupa bastante lugar en nuestra memoria RAM. Además, cada tarea puede llevar mucho tiempo. Entonces, es necesario plantear una estrategia para abordarlo. Existen varias posibilidades, mencionamos algunas:\n",
    "1. Recortar una parte del dataset con la que sí podamos trabajar. Esta parte tiene que ser lo suficientemente representativa del set original. Para estar seguros/as de ello es fundamental hacer una buena exploración de datos. Con ese recorte, entrenamos y evaluamos nuestro modelo, y optimizamos parámetros (CV). Una vez que ya estamos seguro de que nuestro flujo de trabajo es apropiado, podemos probar agrandar la porción de datos con la que entrenamos o utilizar otro recorte del dataset. Eventualmente, podemos llegar a usar todo el dataset para entrenar y evaluar si nuestra computadora lo permite. **NOTA**: el recorte se hace para que se pueda cargar en memoria los datos pero también para que cada iteración lleve un tiempo razonable.\n",
    "2. **Aprendizaje incremental**: algunos modelos puede ser entrenados mostrándoles el dataset de a pedazos. Es decir, no necesitan ver todo el dataset a la vez. Un ejemplo son las redes neuronales, que \"ven\" muchas pasadas del dataset en *epochs* y *minibatches*. Algunos modelos en Scikit-learn tienen la función `partial_fit` que permite hacer eso. Pueden leer un poco al respecto [acá](https://scikit-learn.org/stable/modules/computing.html). Pandas también tiene funciones que permiten cargar el dataset de a trozos.\n",
    "3. Utilizar servicios en la nube. Esta opción no es excluyente con las anteriores. Antes de utilizar algún entorno en la nube, está bueno haber hecho pruebas en nuestra computadora y ya haber optimizado bastante el flujo de trabajo. Recuerden que los servicios en la nube suelen ser pagos.\n",
    "4. Existen librerías orientadas a trabajar con grandes datos. Un ejemplo es [Dask](https://dask.org/).\n",
    "\n",
    "## 0. Algunos preliminares\n",
    "\n",
    "Mientras miras el estado de la memoria RAM - averiguar cómo hacer esto en tu sistema operativo, ¡no es dificil! -, crea un arreglo 2-D de unos en numpy de forma `(10000,10000)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "N = 10000\n",
    "unos = np.ones((N,N))\n",
    "print(unos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del unos # Borra la variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué tipo de dato es `ones`?¿Y sus elementos? Crear el mismo arreglo, pero convertir los elementos en *np.int8*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]\n",
      " ...\n",
      " [1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "unos = np.ones((N,N)).astype(np.int8)\n",
    "print(unos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Ocupa el mismo espacio en memoria?¿Cuál es al diferencia entre un `float` y un `int`?\n",
    "\n",
    "Por las dudas reiniciar el Kernel antes de continuar y correr a partir de la sección siguiente.\n",
    "\n",
    "## 1. Carga de Datos y preparación del Dataset\n",
    "\n",
    "Para comprender los pasos que haremos a continuación, ten en cuenta que necesitamos un dataset donde cada fila represente un usuario, una película y la calificación del usuario a esa película. Es decir, tiras de tres componentes. Hay otra información que puede ser útil, pero con esos tres datos ya podemos implementar un filtro colaborativo.\n",
    "\n",
    "Lamentablemente, el dataset no viene en esa forma, por lo que deberemos preprarar el dataset para adaptarlo a ese formato. Lee detenidamente las celdas de código que te dejamos para preparar el dataset. Pero no te preocupes si no las entiendes del todo. Tal vez descubras que algunas cosas se podrían haber hecho de una manera más simple. ¡No hay una sola forma de hacer las cosas!\n",
    "\n",
    "**Nota:** algunas celdas tardan en correr.\n",
    "\n",
    "Empezamos cargando uno de los archivos con calificaciones para explorarlo. Como son archivos grandes y van a ocupar bastante lugar en memoria, no vamos a cargar la última columna con fechas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import gc #garbage collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24058263, 2)\n"
     ]
    }
   ],
   "source": [
    "def load_data(name):\n",
    "    df = pd.read_csv(name, header = None, names = ['User','Rating'], usecols = [0,1])\n",
    "    return df\n",
    "\n",
    "df1 = load_data('combined_data_1.txt')\n",
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1:</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1488844</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>822109</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>885013</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30878</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      User  Rating\n",
       "0       1:     NaN\n",
       "1  1488844     3.0\n",
       "2   822109     5.0\n",
       "3   885013     4.0\n",
       "4    30878     4.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo sabemos a qué película corresponde cada calificación?¿Dónde está es información? \n",
    "\n",
    "Vamos a contar cuántas películas hay en `df1` e identificarlas. Para ello, cargamos `movie_titles.csv`. Como no nos interesa el año (al menos, por ahora), no lo traemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Movie_Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dinosaur Planet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Isle of Man TT 2004 Review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paula Abdul's Get Up &amp; Dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Rise and Fall of ECW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Name\n",
       "Movie_Id                              \n",
       "1                      Dinosaur Planet\n",
       "2           Isle of Man TT 2004 Review\n",
       "3                            Character\n",
       "4         Paula Abdul's Get Up & Dance\n",
       "5             The Rise and Fall of ECW"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_title = pd.read_csv('movie_titles.csv', encoding = \"ISO-8859-1\",index_col = 0, header = None, usecols = [0,2], names = ['Movie_Id', 'Name'])\n",
    "df_title.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta forma, podemos obtener el nombre de una película dado su `Id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dinosaur Planet\n"
     ]
    }
   ],
   "source": [
    "movie_id = 1\n",
    "print(df_title.loc[movie_id].Name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para contar cuántos identificadores hay, vamos a usar la siguiente información: al lado del identificador de la película, la columna `Rating` de `df1` tiene un `NaN`. Habrán tantas películas como `NaN` haya en rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1:' '2:' '3:' ... '4497:' '4498:' '4499:']\n",
      "4499\n"
     ]
    }
   ],
   "source": [
    "# vemos cuántas películas ha visto cada usuario.\n",
    "\n",
    "movies_ids_df1 = df1.User[df1.Rating.isna()].values\n",
    "print(movies_ids_df1)\n",
    "print(len(movies_ids_df1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿En qué formato está? Si queremos usarlo para pasar de identificador al nombre, debemos llevarlo a enteros. Asumimos que no hay ningun repetido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1    2    3 ... 4497 4498 4499]\n"
     ]
    }
   ],
   "source": [
    "# pasamos el largo de muvie_ids_f1 + 1, para asignar un valor entero a cada posición, de manera de asociarlo al identificador del id de la película.\n",
    "\n",
    "movies_ids_df1 = np.arange(1,len(movies_ids_df1) + 1)\n",
    "print(movies_ids_df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Agregando el Movie_id**\n",
    "\n",
    "`Vamos a agregar una columna al Dataframe con el Id de la película a la que corresponde la calificación.` Es decir, queremos que el DataFrame tenga las siguientes columnas: `User`, `Rating`, `Movie_id`. \n",
    "\n",
    "Para ello, `necesitamos saber dónde están ubicados los identificadores, para completar en el medio con la película correspondiente.`\n",
    "\n",
    "Primero, seleccionamos los índices donde aparecen los identificadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******\n",
      "\n",
      "    Rating\n",
      "0    True\n",
      "1   False\n",
      "2   False\n",
      "3   False\n",
      "4   False\n",
      "5   False\n",
      "6   False \n",
      "\n",
      "\n",
      "******\n",
      "\n",
      "           Rating\n",
      "0           True\n",
      "548         True\n",
      "694         True\n",
      "2707        True\n",
      "2850        True\n",
      "...          ...\n",
      "24046714    True\n",
      "24047329    True\n",
      "24056849    True\n",
      "24057564    True\n",
      "24057834    True\n",
      "\n",
      "[4499 rows x 1 columns] \n",
      "\n",
      " \n",
      " *******\n",
      "\n",
      " [       0      548      694 ... 24056849 24057564 24057834] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creo un df con valores booleanos para rating\n",
    "df1_nan = pd.DataFrame(pd.isnull(df1.Rating))\n",
    "print(\"\\n******\\n\\n\",df1_nan.head(7),\"\\n\")\n",
    "\n",
    "# selecciono de este df, aquellos valores que sean igual a True\n",
    "df1_nan = df1_nan[df1_nan['Rating'] == True]\n",
    "print(\"\\n******\\n\\n\",df1_nan, \"\\n\")\n",
    "\n",
    "# de esta manera identifico mediante qué valor del índice representa el id de la película de index, el id de las películas\n",
    "idx_movies_ids = df1_nan.index.values\n",
    "print(\" \\n *******\\n\\n\", idx_movies_ids, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos crear un vector de tantas instancias como `df1`, donde en cada lugar esté el `Movie_id` al cual corresponde la calificación. Como tenemos los índices donde está cada `Movie_id`, podemos obtener cuántas calificaciones hay de cada película."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Index Number and total rows:  [       0      548      694 ... 24057564 24057834 24058263]\n",
      "\n",
      " N filas para cada ID:  [ 548  146 2013 ...  715  270  429]\n"
     ]
    }
   ],
   "source": [
    "# Creamos un array que muestre los index en los que hay un ID, y le agregamos el número de filas totales del df\n",
    "idx_movies_ids = np.append(idx_movies_ids,df1.shape[0])\n",
    "print(\"\\n Index Number and total rows: \",idx_movies_ids)\n",
    "\n",
    "# calculamos la nth diferencia discreta a lo largo del array, de manera de obtener cuántas filas tiene cada ID\n",
    "cantidad_criticas = np.diff(idx_movies_ids)\n",
    "print(\"\\n N filas para cada ID: \", cantidad_criticas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos la columna movie_id\n",
    "\n",
    "# crea un array\n",
    "columna_movie_id = np.array([])\n",
    "# para cada elemento de cantidadc\n",
    "for i in range(cantidad_criticas.size):\n",
    "    # llena ese elemento con el elemento correspondiente movies_ieds_df1\n",
    "    aux = np.full(cantidad_criticas[i], movies_ids_df1[i])\n",
    "    #concatena columna_movie_id con aux\n",
    "    columna_movie_id = np.concatenate((columna_movie_id, aux))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregamos esa columna al dataset y, ahora sí, convertimos a tipos de datos que ocupen menos lugar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Movie_id'] = columna_movie_id\n",
    "del columna_movie_id\n",
    "\n",
    "df1.dropna(inplace = True)\n",
    "df1['User'] = df1['User'].astype(int)\n",
    "df1['Movie_id'] = df1['Movie_id'].astype(np.int16)\n",
    "df1['Rating'] = df1['Rating'].astype(np.int8)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1488844</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>822109</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>885013</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30878</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>823519</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      User  Rating  Movie_id\n",
       "1  1488844       3         1\n",
       "2   822109       5         1\n",
       "3   885013       4         1\n",
       "4    30878       4         1\n",
       "5   823519       3         1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya contamos con un dataframe con calificaciones de usuarios a películas.\n",
    "\n",
    "Una opción muy útil es guardar el dataset modificado en nuevo archivo y, a partir de ahora, trabajar con esa versión. Esto hará que no tengas que hacer el preprocesamiento cada vez que empieces a trabajar y, además, ahorrarnos toda la \"basura\" que Python pueda ir dejando en la RAM.\n",
    "\n",
    "Por eso, guardamos el dataset modificado en un nuevo archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'netflix-prize-data/combined_data_1_with_movie_id.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-9322a2b9d40f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'netflix-prize-data/combined_data_1_with_movie_id.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[1;32m   3168\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3169\u001b[0m         )\n\u001b[0;32m-> 3170\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             f, handles = get_handle(\n\u001b[0m\u001b[1;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'netflix-prize-data/combined_data_1_with_movie_id.csv'"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    df1.to_csv('netflix-prize-data/combined_data_1_with_movie_id.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploración del Dataset\n",
    "\n",
    "Ahora que ya tenemos un dataset prolijo, es momento de explorarlo.\n",
    "\n",
    "Responde - al menos - las siguientes preguntas, siempre que se pueda con un lindo gráfico (¡pensar bien cómo!):\n",
    "\n",
    "1. ¿Cuántos usuarios únicos hay?\n",
    "1. ¿Cuántas películas calificó cada usuario?\n",
    "1. ¿Cómo es la distribución de las calificaciones?¿Pueden concluir algo de ese gráfico?\n",
    "1. ¿Cómo es la distribución del número de calificaciones por usuario?\n",
    "1. ¿Cuál es la película con más calificaciones?¿Cuántas tiene?¿Y la que menos calificaciones tiene?\n",
    "\n",
    "**¿Se te ocurre alguna otra pregunta para explorar?**Por ejemplo, ¿hay alguna relación entre la cantidad de calificaciones que ponen los/as usuarios/as y el valor de ellas? ¿Usuarios que califican mucho tienden a poner calificaciones positivas o negativas?¿Y los que califican poco?\n",
    "\n",
    "Arrancamos abriendo el dataset ya modificado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import gc #garbage collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('combined_data_1_with_movie_id.csv', dtype={'Rating': np.int8, 'movie_id': np.int16})\n",
    "print(df1.shape)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y los títulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title = pd.read_csv('movie_titles.csv', encoding = \"ISO-8859-1\",index_col = 0, header = None, usecols = [0,2], names = ['Movie_Id', 'Name'])\n",
    "df_title.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ¿Cuántos usuarios únicos hay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df1['User'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ¿Cuántas películas calificó cada usuario?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_by_users = df1.groupby(['User']).count()\n",
    "df1_by_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df1_by_users.Rating, log= True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ¿Cómo es la distribución de las calificaciones?¿Pueden concluir algo de ese gráfico?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Rating'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. ¿Cómo es la distribución del número de calificaciones por usuario?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calificaciones_por_usuario = df1.User.value_counts()\n",
    "calificaciones_por_usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calificaciones_por_usuario.hist(log = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. ¿Cuál es la película con más calificaciones?¿Cuántas tiene?¿Y la que menos calificaciones tiene?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peliculas_por_vistos = df1.Movie_id.value_counts()\n",
    "peliculas_por_vistos.index = df_title.loc[peliculas_por_vistos.index].Name\n",
    "peliculas_por_vistos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,4))\n",
    "peliculas_por_vistos.hist(log = True, bins = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
