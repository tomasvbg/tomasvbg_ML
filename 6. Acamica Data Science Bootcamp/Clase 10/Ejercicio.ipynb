{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercitación\n",
    "\n",
    "Vamos a trabajar con el dataset 'DS_Clase_10_Heart.csv'. Dejamos una breve descripción de qué representan algunas columnas.\n",
    "\n",
    "    -slope_of_peak_exercise_st_segment: the slope of the peak exercise ST segment, an electrocardiography read out indicating quality of blood flow to the heart\n",
    "    -thal: results of thallium stress test measuring blood flow to the heart\n",
    "    -resting_blood_pressure: resting blood pressure\n",
    "    -chest_pain_type: chest pain type\n",
    "    -num_major_vessels: number of major vessels colored by flourosopy\n",
    "    -fasting_blood_sugar_gt_120_mg_per_dl: fasting blood sugar > 120 mg/dl\n",
    "    -resting_ekg_results: resting electrocardiographic results\n",
    "    -serum_cholesterol_mg_per_dl: serum cholestoral in mg/dl\n",
    "    -oldpeak_eq_st_depression: oldpeak = ST depression induced by exercise relative to rest, a measure of abnormality in electrocardiograms\n",
    "    -max_heart_rate_achieved: maximum heart rate achieved (beats per minute)\n",
    "    -exercise_induced_angina: exercise-induced chest pain (0: False, 1: True)\n",
    "\n",
    "**Muy importante:** para responder las consignas, no es necesario que programen *desde cero*. De hecho, es raro programar *desde cero*, sino que todo el tiempo reciclamos código de otros trabajos. Por lo tanto, para responder las preguntas, recuerden dónde hicieron algo similar, copien las celdas pertinentes y adáptenlas a este problema. No nos vamos a cansar de recordarles esto.\n",
    "\n",
    "1. Hacer un análisis exploratorio de datos y responder las siguientes preguntas: \n",
    "    1. ¿Qué tipo de dato hay en cada columna desde el punto de vista de la programación (entero, float, etc.)?¿Qué tipo de dato son según lo visto hoy en la clase (nominal, ordinal, numérico, etc.)?¿Hay alguna relación entre ambos mundo?¿Qué podemos hacer si no sabemos una variable de qué tipo es?\n",
    "    1. ¿Hay alguna columna que puedan descartar para este análisis?\n",
    "    1. ¿Cuántos (y cuáles donde consideren apropiado) son los valores únicos de cada columna?\n",
    "    1. ¿Cómo están correlacionadas las variables? Recuerden descartar las columnas que no tengan números. Interpretar.\n",
    "    \n",
    "2. Usar las herramientas vistas hoy en clase para transformar los datos de las columnas que consideren importante transformar. Una vez hecho eso, vuelvan a hacer el cuadro de correlaciones. ¿Hay información nueva?\n",
    "\n",
    "**Nota**: A medida que vayan respondiendo estas preguntas, ir agregando celdas *markdown* intercaladas con el código donde expliquen brevemente las conclusiones a las que llegaron.\n",
    "\n",
    "**Algunas pistas**:\n",
    "* Para abrir el dataset y ver qué tipos de datos hay en cada columna, y cuántos valores únicos tienen, algunas funcionalidades de Pandas pueden ser útiles.\n",
    "* Para obtener una visión rápida del dataset, hay una función de Seaborn que hace precisamente eso.\n",
    "* Para obtener una linda tabla de correlaciones, en el Notebook de la Clase 7 hay un ejemplo que pueden adaptar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'Clase_DS_Clase_10_Heart.csv' does not exist: b'Clase_DS_Clase_10_Heart.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-344bfc797bd1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Clase_DS_Clase_10_Heart.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\envs\\datascience\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\datascience\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\datascience\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\datascience\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\datascience\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'Clase_DS_Clase_10_Heart.csv' does not exist: b'Clase_DS_Clase_10_Heart.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Clase_DS_Clase_10_Heart.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercitación\n",
    "\n",
    "Vamos a trabajar con el dataset 'DS_Clase_10_Heart.csv'. Dejamos una breve descripción de qué representan algunas columnas.\n",
    "\n",
    "    -slope_of_peak_exercise_st_segment: the slope of the peak exercise ST segment, an electrocardiography read out indicating quality of blood flow to the heart\n",
    "    -thal: results of thallium stress test measuring blood flow to the heart\n",
    "    -resting_blood_pressure: resting blood pressure\n",
    "    -chest_pain_type: chest pain type\n",
    "    -num_major_vessels: number of major vessels colored by flourosopy\n",
    "    -fasting_blood_sugar_gt_120_mg_per_dl: fasting blood sugar > 120 mg/dl\n",
    "    -resting_ekg_results: resting electrocardiographic results\n",
    "    -serum_cholesterol_mg_per_dl: serum cholestoral in mg/dl\n",
    "    -oldpeak_eq_st_depression: oldpeak = ST depression induced by exercise relative to rest, a measure of abnormality in electrocardiograms\n",
    "    -max_heart_rate_achieved: maximum heart rate achieved (beats per minute)\n",
    "    -exercise_induced_angina: exercise-induced chest pain (0: False, 1: True)\n",
    "\n",
    "**Muy importante:** para responder las consignas, no es necesario que programen *desde cero*. De hecho, es raro programar *desde cero*, sino que todo el tiempo reciclamos código de otros trabajos. Por lo tanto, para responder las preguntas, recuerden dónde hicieron algo similar, copien las celdas pertinentes y adáptenlas a este problema. No nos vamos a cansar de recordarles esto.\n",
    "\n",
    "1. Hacer un análisis exploratorio de datos y responder las siguientes preguntas: \n",
    "    1. ¿Qué tipo de dato hay en cada columna desde el punto de vista de la programación (entero, float, etc.)?¿Qué tipo de dato son según lo visto hoy en la clase (nominal, ordinal, numérico, etc.)?¿Hay alguna relación entre ambos mundo?¿Qué podemos hacer si no sabemos una variable de qué tipo es?\n",
    "    1. ¿Hay alguna columna que puedan descartar para este análisis?\n",
    "    1. ¿Cuántos (y cuáles donde consideren apropiado) son los valores únicos de cada columna?\n",
    "    1. ¿Cómo están correlacionadas las variables? Recuerden descartar las columnas que no tengan números. Interpretar.\n",
    "    \n",
    "2. Usar las herramientas vistas hoy en clase para transformar los datos de las columnas que consideren importante transformar. Una vez hecho eso, vuelvan a hacer el cuadro de correlaciones. ¿Hay información nueva?\n",
    "\n",
    "**Nota**: A medida que vayan respondiendo estas preguntas, ir agregando celdas *markdown* intercaladas con el código donde expliquen brevemente las conclusiones a las que llegaron.\n",
    "\n",
    "**Algunas pistas**:\n",
    "* Para abrir el dataset y ver qué tipos de datos hay en cada columna, y cuántos valores únicos tienen, algunas funcionalidades de Pandas pueden ser útiles.\n",
    "* Para obtener una visión rápida del dataset, hay una función de Seaborn que hace precisamente eso.\n",
    "* Para obtener una linda tabla de correlaciones, en el Notebook de la Clase 7 hay un ejemplo que pueden adaptar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercitación\n",
    "\n",
    "Vamos a trabajar con el dataset 'DS_Clase_10_Heart.csv'. Dejamos una breve descripción de qué representan algunas columnas.\n",
    "\n",
    "    -slope_of_peak_exercise_st_segment: the slope of the peak exercise ST segment, an electrocardiography read out indicating quality of blood flow to the heart\n",
    "    -thal: results of thallium stress test measuring blood flow to the heart\n",
    "    -resting_blood_pressure: resting blood pressure\n",
    "    -chest_pain_type: chest pain type\n",
    "    -num_major_vessels: number of major vessels colored by flourosopy\n",
    "    -fasting_blood_sugar_gt_120_mg_per_dl: fasting blood sugar > 120 mg/dl\n",
    "    -resting_ekg_results: resting electrocardiographic results\n",
    "    -serum_cholesterol_mg_per_dl: serum cholestoral in mg/dl\n",
    "    -oldpeak_eq_st_depression: oldpeak = ST depression induced by exercise relative to rest, a measure of abnormality in electrocardiograms\n",
    "    -max_heart_rate_achieved: maximum heart rate achieved (beats per minute)\n",
    "    -exercise_induced_angina: exercise-induced chest pain (0: False, 1: True)\n",
    "\n",
    "**Muy importante:** para responder las consignas, no es necesario que programen *desde cero*. De hecho, es raro programar *desde cero*, sino que todo el tiempo reciclamos código de otros trabajos. Por lo tanto, para responder las preguntas, recuerden dónde hicieron algo similar, copien las celdas pertinentes y adáptenlas a este problema. No nos vamos a cansar de recordarles esto.\n",
    "\n",
    "1. Hacer un análisis exploratorio de datos y responder las siguientes preguntas: \n",
    "    1. ¿Qué tipo de dato hay en cada columna desde el punto de vista de la programación (entero, float, etc.)?¿Qué tipo de dato son según lo visto hoy en la clase (nominal, ordinal, numérico, etc.)?¿Hay alguna relación entre ambos mundo?¿Qué podemos hacer si no sabemos una variable de qué tipo es?\n",
    "    1. ¿Hay alguna columna que puedan descartar para este análisis?\n",
    "    1. ¿Cuántos (y cuáles donde consideren apropiado) son los valores únicos de cada columna?\n",
    "    1. ¿Cómo están correlacionadas las variables? Recuerden descartar las columnas que no tengan números. Interpretar.\n",
    "    \n",
    "2. Usar las herramientas vistas hoy en clase para transformar los datos de las columnas que consideren importante transformar. Una vez hecho eso, vuelvan a hacer el cuadro de correlaciones. ¿Hay información nueva?\n",
    "\n",
    "**Nota**: A medida que vayan respondiendo estas preguntas, ir agregando celdas *markdown* intercaladas con el código donde expliquen brevemente las conclusiones a las que llegaron.\n",
    "\n",
    "**Algunas pistas**:\n",
    "* Para abrir el dataset y ver qué tipos de datos hay en cada columna, y cuántos valores únicos tienen, algunas funcionalidades de Pandas pueden ser útiles.\n",
    "* Para obtener una visión rápida del dataset, hay una función de Seaborn que hace precisamente eso.\n",
    "* Para obtener una linda tabla de correlaciones, en el Notebook de la Clase 7 hay un ejemplo que pueden adaptar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
