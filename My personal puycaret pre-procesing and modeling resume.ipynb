{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Modeling in Pycaret\n",
    "\n",
    "Tomás von Bischoffshausen Gariazzo\n",
    "\n",
    "January, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Sample and Split\n",
    "\n",
    "**1.1 Train Test Split** \n",
    "\n",
    "**Machine Learning Goal** is to build a model that generalizes well to the new data. Hence the dataset is split into the Train dataset and the Test dataset during supervised machine learning experiment. Test dataset serves as a proxy for new data. \n",
    "\n",
    "**Training set**\n",
    "Evaluation of a trained machine learning model and optimization of the hyperparameters in PyCaret is performed using k-fold cross validation on Train dataset only. \n",
    "\n",
    "**Test Set**\n",
    "Test dataset (also known as hold-out set) is not used in training of models and hence can be used under predict_model function to evaluate metrics and determine if the model has over-fitted the data. \n",
    "\n",
    "**Train Size**\n",
    "By default, PyCaret uses 70% of the dataset for training, which can be changed using train_size parameter within setup. This functionality is only available in pycaret.classification and pycaret.regression modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "from pycaret.datasets import get_data\n",
    "insurance = get_data('insurance')\n",
    "\n",
    "# Importing module and initializing setup\n",
    "from pycaret.regression import *\n",
    "reg1 = setup(data = insurance, target = 'charges', train_size = 0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 Sampling**\n",
    "\n",
    "**¿Why sampling?**\n",
    "Sometimes, you may want to choose a smaller sample size to train models faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "from pycaret.datasets import get_data\n",
    "bank = get_data('bank')\n",
    " \n",
    "# Importing module and initializing setup\n",
    "from pycaret.regression import *\n",
    "reg1 = setup(data = bank, target = 'deposit') #sampling = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 Missing Value Imputation**\n",
    "\n",
    "**Missing values importance**\n",
    "Datasets for various reasons may have missing values or empty records, often encoded as blanks or NaN. Most of the machine learning algorithms are not capable of dealing with missing or blank values. \n",
    " \n",
    "**Treat them, not delete them**\n",
    "Removing samples with missing values is a basic strategy that is sometimes used but it comes with a cost of losing probable valuable data and the associated information or patterns. A better strategy is to impute the missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "from pycaret.datasets import get_data\n",
    "hepatitis = get_data('hepatitis')\n",
    "\n",
    "# Importing module and initializing setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data = hepatitis, target = 'Class'\n",
    "            #, numeric_imputation = \"mean\",\n",
    "            # categorichal_imputation = \"constant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 Change Data Types**\n",
    "\n",
    "**Data Types**\n",
    "Each feature in the dataset has an associated data type such as numeric feature, categorical feature or date-time feature. \n",
    "\n",
    "**Why ensuring data types are correct?**\n",
    "Several downstream processes depend on the data type of the features, for example: missing value imputation for numeric and categorical features should be performed separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "from pycaret.datasets import get_data\n",
    "hepatitis = get_data('hepatitis')\n",
    "\n",
    "# Importing module and initializing setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data = hepatitis, \n",
    "             target = 'Class', \n",
    "             categorical_features = ['AGE']\n",
    "             #, numeric_features = [‘column1’]\n",
    "\n",
    "# Importing dataset\n",
    "from pycaret.datasets import get_data\n",
    "pokemon = get_data('pokemon')\n",
    "\n",
    "# Importing module and initializing setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data = pokemon, \n",
    "             target = 'Legendary', \n",
    "             ignore_features = ['#', 'Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3 One Hot Encoding**\n",
    "\n",
    "**Why encoding?**\n",
    "Machine learning algorithms cannot work directly with categorical data and they must be transformed into numeric values before training a model.\n",
    "\n",
    "**What is one hot encoding?**\n",
    "Most common type of categorical encoding is One Hot Encoding (also known as dummy encoding) where each categorical level becomes a separate feature in the dataset containing binary values (1 or 0). \n",
    "\n",
    "\n",
    "**One hot encoding in Pycaret**\n",
    "Since this is an imperative step to perform a ML experiment, PyCaret will transform all categorical features in dataset using one hot encoding. This is ideal for features having nominal categorical data i.e. data cannot be ordered. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "from pycaret.datasets import get_data\n",
    "pokemon = get_data('pokemon')\n",
    " \n",
    "# Importing module and initializing setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data = pokemon,\n",
    "             target = 'Legendary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4 Ordinal Encoding**\n",
    " \n",
    "**Why ordinal encoding?**\n",
    "When categorical features in the dataset contain variables with intrinsic natural order such as Low, Medium and High, these must be encoded differently than nominal variables (where there is no intrinsic order for e.g. Male or Female). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "from pycaret.datasets import get_data\n",
    "employee = get_data('employee')\n",
    "\n",
    "# Importing module and initializing setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data = employee, \n",
    "             target = 'left', \n",
    "             ordinal_features = {'salary' : ['low', 'medium', 'high']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5 Cardinal Econding**\n",
    "\n",
    "**Why cardinal encoding?**\n",
    "When categorical features in the dataset contain variables with many levels (also known as high cardinality features), then typical One Hot Encoding leads to creation of a very large number of new features, thereby making the experiment slow and introduces probable noise for certain machine learning algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "from pycaret.datasets import get_data\n",
    "income = get_data('income')\n",
    " \n",
    "# Importing module and initializing setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data = income, \n",
    "             target = 'income >50K', \n",
    "             high_cardinality_features = ['native-country'],\n",
    "            # high_cardinality_method = ‘frequency’/\"clustering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.6 Handle Unknown Levels**\n",
    "\n",
    "**¿Why handle unknown levels?**\n",
    "When the unseen data has new levels in categorical feature that were not present at the time of training the model, it may cause problems for trained algorithm in generating accurate predictions. \n",
    "\n",
    "**What can be done?**\n",
    "One way to deal with such data points is to reassign them to known level of categorical features i.e. the levels known in the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing module and initializing setup\n",
    "from pycaret.regression import *\n",
    "reg1 = setup(data = insurance, target = 'charges', \n",
    "             handle_unknown_categorical = True, \n",
    "             unknown_categorical_method = 'most_frequent'#/last frequent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Scale and Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1 Normalization**\n",
    "\n",
    "**¿What is normalization?**\n",
    "Normalization is a technique often applied as part of data preparation for machine learning. The goal of normalization is to rescale the values of numeric columns in the dataset without distorting differences in the ranges of values or losing information. \n",
    "\n",
    "**Normalization methods**\n",
    "\n",
    "z-score : The standard zscore is calculated as z = (x – u) / s \n",
    "\n",
    "minmax : scales and translates each feature individually such that it is in the range of 0 – 1. \n",
    "\n",
    "maxabs : scales and translates each feature individually such that the maximal absolute value of each feature will be 1.0. \n",
    "\n",
    "robust : scales and translates each feature according to the Interquartile range. When the dataset contains outliers, robust scaler often gives better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "from pycaret.datasets import get_data\n",
    "pokemon = get_data('pokemon')\n",
    " \n",
    "# Importing module and initializing setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data = pokemon, \n",
    "             target = 'Legendary', \n",
    "             normalize = True, \n",
    "             #normalize_method = \"zscore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2 Transformation**\n",
    "\n",
    "**What is transformation?**\n",
    "While normalization rescales the data within new limits to reduce the impact of magnitude in the variance, Transformation is a more radical technique. Transformation changes the shape of the distribution such that the transformed data can be represented by a normal or approximate normal distribution. In general, data must be transformed when using ML algorithms that assume normality or a gaussian distribution in the residuals. Examples of such models are Logistic Regression, Linear Discriminant Analysis (LDA) and Gaussian Naive Bayes. \n",
    "\n",
    "**Transformation Methods**\n",
    "\n",
    "**transformation: bool, default = False** When set to True, a power transformation is applied to make the data more normal / Gaussian-like. This is useful for modeling issues related to heteroscedasticity or other situations where normality is desired. The optimal parameter for stabilizing variance and minimizing skewness is estimated through maximum likelihood. \n",
    "\n",
    "**transformation_method: string, default = ‘yeo-johnson’** Defines the method for transformation. By default, the transformation method is set to ‘yeo-johnson’. The other available option is ‘quantile’ transformation. Both the transformation transforms the feature set to follow a Gaussian-like or normal distribution. Note that the quantile transformer is non-linear and may distort linear correlations between variables measured at the same scale.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "from pycaret.datasets import get_data\n",
    "pokemon = get_data('pokemon')\n",
    " \n",
    "# Importing module and initializing setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data = pokemon, \n",
    "             target = 'Legendary', \n",
    "             transformation = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3 Target Transformation**\n",
    "Is similar to transformation as it is used to change the shape of the distribution of target variable. Target must be transformed when linear algorithms such as Linear Regression or Linear Discriminant Analysis are used for modeling. \n",
    " \n",
    "**transform_target: bool, default = False** When set to True, target variable is transformed using the method defined in transform_target_method param. Target transformation is applied separately from feature transformations. \n",
    "\n",
    "**transform_target_method: string, default = ‘box-cox’**\n",
    "‘Box-cox’ and ‘yeo-johnson’ methods are supported. Box-Cox requires input data to be strictly positive, while Yeo-Johnson supports both positive or negative data. When transform_target_method is ‘box-cox’ and target variable contains negative values, method is internally forced to ‘yeo-johnson’ to avoid exceptions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "from pycaret.datasets import get_data\n",
    "diamond = get_data('diamond')\n",
    " \n",
    "# Importing module and initializing setup\n",
    "from pycaret.regression import *\n",
    "reg1 = setup(data = diamond, target = 'Price', transform_target = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Feature Engineer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Interaction**\n",
    "\n",
    "It is often seen in machine learning experiments when two features combined through an arithmetic operation becomes more significant in explaining variances in the data, than the same two features separately. Creating a new feature through interaction of existing features is known as feature interaction. It can achieved in PyCaret using feature_interaction and feature_ratio parameters within setup. Feature interaction creates new features by multiplying two variables (a * b), while feature ratios create new features but by calculating the ratios of existing features (a / b).\n",
    "\n",
    "feature_interaction: bool, default = False When set to True, it will create new features by interacting (a * b) for all numeric variables in the dataset including polynomial and trigonometric features (if created). This feature is not scalable and may not work as expected on datasets with large feature space. feature_ratio: bool, default = False When set to True, it will create new features by calculating the ratios (a / b) of all numeric variables in the dataset. This feature is not scalable and may not work as expected on datasets with large feature space. interaction_threshold: bool, default = 0.01 Similar to polynomial_threshold, It is used to compress a sparse matrix of newly created features through interaction. Features whose importance based on the combination of Random Forest, AdaBoost and Linear correlation falls within the percentile of the defined threshold are kept in the dataset. Remaining features are dropped before further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "from pycaret.datasets import get_data\n",
    "insurance = get_data('insurance')\n",
    " \n",
    "# Importing module and initializing setup\n",
    "from pycaret.regression import *\n",
    "reg1 = setup(data = insurance, target = 'charges', feature_interaction = True, feature_ratio = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2 Polynomial Features**\n",
    "\n",
    "In machine learning experiments the relationship between the dependent and independent variable is often assumed as linear, however this is not always the case. Sometimes the relationship between dependent and independent variables is more complex. Creating new polynomial features sometimes might help in capturing that relationship which otherwise may go unnoticed. PyCaret can create polynomial features from existing features using \n",
    " \n",
    "polynomial_features parameter within setup. polynomial_features: bool, default = False\n",
    "When set to True, new features are created based on all polynomial combinations that exist within the numeric features in a dataset to the degree defined in polynomial_degree param.\n",
    "polynomial_degree: int, default = 2 Degree of polynomial features. For example, if an input sample is two dimensional and of the form [a, b], the polynomial features with degree = 2 are: [1, a, b, a^2, ab, b^2]. polynomial_threshold: float, default = 0.1 This is used to compress a sparse matrix of polynomial and trigonometric features. Polynomial and trigonometric features whose feature importance based on the combination of Random Forest, AdaBoost and Linear correlation falls within the percentile of the defined threshold are kept in the dataset. Remaining features are dropped before further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "from pycaret.datasets import get_data\n",
    "juice = get_data('juice')\n",
    " \n",
    "# Importing module and initializing setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data = juice, target = 'Purchase', polynomial_features = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3 Trigonometry Features**\n",
    "\n",
    "Similar to Polynomial Features, PyCaret also allows creating new trigonometry features from the existing features. It is achieved using trigonometry_features parameter within setup. trigonometry_features: bool, default = False. When set to True, new features are created based on all trigonometric combinations that exist within the numeric features in a dataset to the degree defined in the polynomial_degree param.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "from pycaret.datasets import get_data\n",
    "insurance = get_data('insurance')\n",
    "\n",
    "# Importing module and initializing setup\n",
    "from pycaret.regression import *\n",
    "reg1 = setup(data = insurance, target = 'charges', trigonometry_features = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.4 Group Features**\n",
    "\n",
    "When dataset contains features that are related to each other in someway, for example: features recorded at some fixed time intervals, then new statistical features such as mean, median, variance and standard deviation for a group of such features can be created from existing features using group_features parameter within setup.\n",
    "\n",
    "group_features: list or list of list, default = None When a dataset contains features that have related characteristics, the group_features param can be used for statistical feature extraction. For example, if a dataset has numeric features that are related with each other (i.e ‘Col1’, ‘Col2’, ‘Col3’), a list containing the column names can be passed under group_features to extract statistical information such as the mean, median, mode and standard deviation. group_names: list, default = None When group_features is passed, a name of the group can be passed into the group_names param as a list containing strings. The length of a group_names list must equal to the length of group_features. When the length doesn’t match or the name is not passed, new features are sequentially named such as group_1, group_2 etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.datasets import get_data\n",
    "credit = get_data('credit')\n",
    " \n",
    "# Importing module and initializing setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data = credit, target = 'default', group_features = ['BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.5 Bin Numeric Features**\n",
    "Feature binning is a method of turning continuous variables into categorical values using pre-defined number of bins. It is effective when a continuous feature has too many unique values or few extreme values outside the expected range. Such extreme values influence on the trained model, thereby affecting the prediction accuracy of the model. In PyCaret, continuous numeric features can be binned into intervals using bin_numeric_features parameter within setup. PyCaret uses the ‘sturges’ rule to determine the number of bins and also uses K-Means clustering to convert continuous numeric features into categorical features.\n",
    "\n",
    "bin_numeric_features: list, default = None\n",
    "When a list of numeric features is passed they are transformed into categorical features using K-Means, where values in each bin have the same nearest center of a 1D k-means cluster. The number of clusters are determined based on the ‘sturges’ method. It is only optimal for gaussian data and underestimates the number of bins for large non-gaussian datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "from pycaret.datasets import get_data\n",
    "income = get_data('income')\n",
    "\n",
    "# Importing module and initializing setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data = income, target = 'income >50K', bin_numeric_features = ['age'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.6 Combine Rare Levels\n",
    "Sometimes a dataset can have a categorical feature (or multiple categorical features) that has a very high number of levels (i.e. high cardinality features). If such feature (or features) are encoded into numeric values, then the resultant matrix is a sparse matrix. This not only makes experiment slow due to manifold increment in the number of features and hence the size of the dataset, but also introduces noise in the experiment. Sparse matrix can be avoided by combining the rare levels in the feature(or features) having high cardinality. This can be achieved in PyCaret using combine_rare_levels parameter within setup.\n",
    "\n",
    "combine_rare_levels: bool, default = False When set to True, all levels in categorical features below the threshold defined in rare_level_threshold param are combined together as a single level. There must be at least two levels under the threshold for this to take effect. rare_level_threshold represents the percentile distribution of level frequency. Generally, this technique is applied to limit a sparse matrix caused by high numbers of levels in categorical features. rare_level_threshold: float, default = 0.1 Percentile distribution below which rare categories are combined. Only comes into effect when combine_rare_levels is set to True.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "from pycaret.datasets import get_data\n",
    "income = get_data('income')\n",
    " \n",
    "# Importing module and initializing setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data = income, target = 'income >50K', combine_rare_levels = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.1 Feature Importance**\n",
    "\n",
    "Feature Importance is a process used to select features in the dataset that contributes the most in predicting the target variable. Working with selected features instead of all the features reduces the risk of over-fitting, improves accuracy, and decreases the training time. In PyCaret, this can be achieved using feature_selection parameter. It uses a combination of several supervised feature selection techniques to select the subset of features that are most important for modeling. The size of the subset can be controlled using feature_selection_threshold parameter within setup.\n",
    "\n",
    "feature_selection: bool, default = False When set to True, a subset of features are selected using a combination of various permutation importance techniques including Random Forest, Adaboost and Linear correlation with target variable. The size of the subset is dependent on the feature_selection_param. Generally, this is used to constrain the feature space in order to improve efficiency in modeling. When polynomial_features and feature_interaction are used, it is highly recommended to define the feature_selection_threshold param with a lower value. feature_selection_threshold: float, default = 0.8 Threshold used for feature selection (including newly created polynomial features). A higher value will result in a higher feature space. It is recommended to do multiple trials with different values of feature_selection_threshold specially in cases where polynomial_features and feature_interaction are used. Setting a very low value may be efficient but could result in under-fitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "from pycaret.datasets import get_data\n",
    "diabetes = get_data('diabetes')\n",
    " \n",
    "# Importing module and initializing setup\n",
    "from pycaret.regression import *\n",
    "clf1 = setup(data = diabetes, target = 'Class variable', feature_selection = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5.2 Remove Multicollinearity\n",
    "Multicollinearity (also called collinearity) is a phenomenon in which one feature variable in the dataset is highly linearly correlated with another feature variable in the same dataset. Multicollinearity increases the variance of the coefficients, thus making them unstable and noisy for linear models. One such way to deal with Multicollinearity is to drop one of the two features that are highly correlated with each other. This can be achieved in PyCaret using remove_multicollinearity parameter within setup.\n",
    "\n",
    "remove_multicollinearity: bool, default = False When set to True, the variables with inter-correlations higher than the threshold defined under the multicollinearity_threshold param are dropped. When two features are highly correlated with each other, the feature that is less correlated with the target variable is dropped. multicollinearity_threshold: float, default = 0.9 Threshold used for dropping the correlated features. Only comes into effect when remove_multicollinearity is set to True.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "from pycaret.datasets import get_data\n",
    "concrete = get_data('concrete')\n",
    "\n",
    "# Importing module and initializing setup\n",
    "from pycaret.regression import *\n",
    "reg1 = setup(data = concrete, target = 'strength', remove_multicollinearity = True, multicollinearity_threshold = 0.6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3 Principal Component Analysis\n",
    "Principal Component Analysis (PCA) is an unsupervised technique used in machine learning to reduce the dimensionality of a data. It does so by compressing the feature space by identifying a subspace that captures most of the information in the complete feature matrix. It projects the original feature space into lower dimensionality. This can be achieved in PyCaret using pca parameter within setup.\n",
    "\n",
    "pca: bool, default = False When set to True, dimensionality reduction is applied to project the data into a lower dimensional space using the method defined in pca_method param. In supervised learning pca is generally performed when dealing with high feature space and memory is a constraint. Note that not all datasets can be decomposed efficiently using a linear PCA technique and that applying PCA may result in loss of information. As such, it is advised to run multiple experiments with different pca_methods to evaluate the impact. pca_method: string, default = ‘linear’ The ‘linear’ method performs Linear dimensionality reduction using Singular Value Decomposition. The other available options are: kernel : dimensionality reduction through the use of RVF kernel. incremental : replacement for ‘linear’ pca when the dataset to be decomposed is too large to fit in memory. pca_components: int/float, default = 0.99 Number of components to keep. if pca_components is a float, it is treated as a target percentage for information retention. When pca_components is an integer it is treated as the number of features to be kept. pca_components must be strictly less than the original number of features in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "from pycaret.datasets import get_data\n",
    "income = get_data('income')\n",
    "\n",
    "# Importing module and initializing setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data = income, target = 'income >50K', pca = True, pca_components = 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.4 Ignore Low Variance**\n",
    "\n",
    "Sometimes a dataset may have a categorical feature with multiple levels, where distribution of such levels are skewed and one level may dominate over other levels. This means there is not much variation in the information provided by such feature.  For a ML model, such feature may not add a lot of information and thus can be ignored for modeling. This can be achieved in PyCaret using ignore_low_variance parameter within setup. Both conditions below must be met for a feature to be considered a low variance feature. Count of unique values in a feature  / sample size < 10% Count of most common value / Count of second most common value > 20 times.\n",
    " \n",
    "ignore_low_variance: bool, default = False\n",
    "When set to True, all categorical features with statistically insignificant variances are removed from the dataset. The variance is calculated using the ratio of unique  values to the number of samples, and the ratio of the most common value to the frequency of the second most common value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "from pycaret.datasets import get_data\n",
    "mice = get_data('mice')\n",
    " \n",
    "# Filter the column to demonstrate example\n",
    "mice = mice[mice['Genotype']] = 'Control'\n",
    " \n",
    "# Importing module and initializing setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data = mice, target = 'class', ignore_low_variance = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. (v2) Unsupervised Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.1 (v2) Create clusters**\n",
    "\n",
    "Creating Clusters using the existing features from the data is an unsupervised ML technique to engineer and create new features. It uses iterative approach to determine the number of clusters using combination of Calinski-Harabasz and Silhouette criterion. Each data point with the original features is assigned to a cluster. The assigned cluster label is then used as a new feature in predicting target variable. This can be achieved in PyCaret using create_clusters parameter within setup.\n",
    "\n",
    "create_clusters: bool, default = False When set to True, an additional feature is created where each instance is assigned to a cluster. The number of clusters is determined using a combination of Calinski-Harabasz and Silhouette criterion. cluster_iter: int, default = 20 Number of iterations used to create a cluster. Each iteration represents cluster size. Only comes into effect when create_clusters param is set to True.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "from pycaret.datasets import get_data\n",
    "insurance = get_data('insurance')\n",
    " \n",
    "# Importing module and initializing setup\n",
    "from pycaret.regression import *\n",
    "reg1 = setup(data = insurance, target = 'charges', create_clusters = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.1 (v2) Remove Outliers**\n",
    "\n",
    "The Remove Outliers function in PyCaret allows you to identify and remove outliers from the dataset before training the model. Outliers are identified through PCA linear dimensionality reduction using the Singular Value Decomposition technique. It can be achieved using remove_outliers parameter within setup. The proportion of outliers are controlled through outliers_threshold parameter.\n",
    "\n",
    "remove_outliers: bool, default = False When set to True, outliers from the training data are removed using PCA linear dimensionality reduction using the Singular Value Decomposition technique. outliers_threshold: float, default = 0.05 The percentage / proportion of outliers in the dataset can be defined using the outliers_threshold param. By default, 0.05 is used which means 0.025 of the values on each side of the distribution’s tail are dropped from training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "from pycaret.datasets import get_data\n",
    "insurance = get_data('insurance')\n",
    "\n",
    "# Importing module and initializing setup\n",
    "from pycaret.regression import *\n",
    "reg1 = setup(data = insurance, target = 'charges', remove_outliers = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.1 Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification setup functions**\n",
    "\n",
    "This function initializes the training environment and creates the transformation pipeline. Setup function must be called before executing any other function. It takes two mandatory parameters: data and target. All the other parameters are optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.datasets import get_data\n",
    "juice = get_data('juice')\n",
    "from pycaret.classification import *\n",
    "exp_name = setup(data = juice,  target = 'Purchase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycaret.classification.setup(data: pandas.core.frame.DataFrame, \n",
    "                             target: str, train_size: float = 0.7, \n",
    "                             test_data: Optional[pandas.core.frame.DataFrame] = None, \n",
    "                             preprocess: bool = True, \n",
    "                             imputation_type: str = 'simple', \n",
    "                             iterative_imputation_iters: int = 5, \n",
    "                             categorical_features: Optional[List[str]] = None, \n",
    "                             categorical_imputation: str = 'constant', \n",
    "                             categorical_iterative_imputer: Union[str, Any] = 'lightgbm', \n",
    "                             ordinal_features: Optional[Dict[str, list]] = None, \n",
    "                             high_cardinality_features: Optional[List[str]] = None, \n",
    "                             high_cardinality_method: str = 'frequency', \n",
    "                             numeric_features: Optional[List[str]] = None, \n",
    "                             numeric_imputation: str = 'mean', \n",
    "                             numeric_iterative_imputer: Union[str, Any] = 'lightgbm', \n",
    "                             date_features: Optional[List[str]] = None, \n",
    "                             ignore_features: Optional[List[str]] = None, \n",
    "                             normalize: bool = False, \n",
    "                             normalize_method: str = 'zscore', \n",
    "                             transformation: bool = False, \n",
    "                             transformation_method: str = 'yeo-johnson', \n",
    "                             handle_unknown_categorical: bool = True, \n",
    "                             unknown_categorical_method: str = 'least_frequent', \n",
    "                             pca: bool = False, \n",
    "                             pca_method: str = 'linear', \n",
    "                             pca_components: Optional[float] = None, \n",
    "                             ignore_low_variance: bool = False, \n",
    "                             combine_rare_levels: bool = False, \n",
    "                             rare_level_threshold: float = 0.1, \n",
    "                             bin_numeric_features: Optional[List[str]] = None, \n",
    "                             remove_outliers: bool = False, \n",
    "                             outliers_threshold: float = 0.05, \n",
    "                             remove_multicollinearity: bool = False, \n",
    "                             multicollinearity_threshold: float = 0.9, \n",
    "                             remove_perfect_collinearity: bool = True, \n",
    "                             create_clusters: bool = False, \n",
    "                             cluster_iter: int = 20, \n",
    "                             polynomial_features: bool = False, \n",
    "                             polynomial_degree: int = 2, \n",
    "                             trigonometry_features: bool = False, \n",
    "                             polynomial_threshold: float = 0.1, \n",
    "                             group_features: Optional[List[str]] = None, \n",
    "                             group_names: Optional[List[str]] = None, \n",
    "                             feature_selection: bool = False, \n",
    "                             feature_selection_threshold: float = 0.8, \n",
    "                             feature_selection_method: str = 'classic', \n",
    "                             feature_interaction: bool = False, feature_ratio: bool = False, \n",
    "                             interaction_threshold: float = 0.01, \n",
    "                             fix_imbalance: bool = False, \n",
    "                             fix_imbalance_method: Optional[Any] = None, \n",
    "                             data_split_shuffle: bool = True, \n",
    "                             data_split_stratify: Union[bool, List[str]] = False, \n",
    "                             fold_strategy: Union[str, Any] = 'stratifiedkfold', \n",
    "                             fold: int = 10, fold_shuffle: bool = False, \n",
    "                             fold_groups: Optional[Union[str, pandas.core.frame.DataFrame]] = None, \n",
    "                             n_jobs: Optional[int] = - 1, \n",
    "                             use_gpu: bool = False, \n",
    "                             custom_pipeline: Optional[Union[Any, Tuple[str, Any], \n",
    "                             List[Any], \n",
    "                             List[Tuple[str, Any]]]] = None, html: bool = True, session_id: Optional[int] = None, log_experiment: bool = False, experiment_name: Optional[str] = None, log_plots: Union[bool, list] = False, log_profile: bool = False, log_data: bool = False, silent: bool = False, verbose: bool = True, \n",
    "                             profile: bool = False, \n",
    "                             profile_kwargs: Optional[Dict[str, Any]] = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data: pandas.DataFrame\n",
    "Shape (n_samples, n_features), where n_samples is the number of samples and n_features is the number of features.\n",
    "\n",
    "target: str\n",
    "Name of the target column to be passed in as a string. The target variable can be either binary or multiclass.\n",
    "\n",
    "train_size: float, default = 0.7\n",
    "Proportion of the dataset to be used for training and validation. Should be between 0.0 and 1.0.\n",
    "\n",
    "test_data: pandas.DataFrame, default = None\n",
    "If not None, test_data is used as a hold-out set and train_size parameter is ignored. test_data must be labelled and the shape of data and test_data must match.\n",
    "\n",
    "preprocess: bool, default = True\n",
    "When set to False, no transformations are applied except for train_test_split and custom transformations passed in custom_pipeline param. Data must be ready for modeling (no missing values, no dates, categorical data encoding), when preprocess is set to False.\n",
    "\n",
    "imputation_type: str, default = ‘simple’\n",
    "The type of imputation to use. Can be either ‘simple’ or ‘iterative’.\n",
    "\n",
    "iterative_imputation_iters: int, default = 5\n",
    "Number of iterations. Ignored when imputation_type is not ‘iterative’.\n",
    "\n",
    "categorical_features: list of str, default = None\n",
    "If the inferred data types are not correct or the silent param is set to True, categorical_features param can be used to overwrite or define the data types. It takes a list of strings with column names that are categorical.\n",
    "\n",
    "categorical_imputation: str, default = ‘constant’\n",
    "Missing values in categorical features are imputed with a constant ‘not_available’ value. The other available option is ‘mode’.\n",
    "\n",
    "categorical_iterative_imputer: str, default = ‘lightgbm’\n",
    "Estimator for iterative imputation of missing values in categorical features. Ignored when imputation_type is not ‘iterative’.\n",
    "\n",
    "ordinal_features: dict, default = None\n",
    "Encode categorical features as ordinal. For example, a categorical feature with ‘low’, ‘medium’, ‘high’ values where low < medium < high can be passed as ordinal_features = { ‘column_name’ : [‘low’, ‘medium’, ‘high’] }.\n",
    "\n",
    "high_cardinality_features: list of str, default = None\n",
    "When categorical features contains many levels, it can be compressed into fewer levels using this parameter. It takes a list of strings with column names that are categorical.\n",
    "\n",
    "high_cardinality_method: str, default = ‘frequency’\n",
    "Categorical features with high cardinality are replaced with the frequency of values in each level occurring in the training dataset. Other available method is ‘clustering’ which trains the K-Means clustering algorithm on the statistical attribute of the training data and replaces the original value of feature with the cluster label. The number of clusters is determined by optimizing Calinski-Harabasz and Silhouette criterion.\n",
    "\n",
    "numeric_features: list of str, default = None\n",
    "If the inferred data types are not correct or the silent param is set to True, numeric_features param can be used to overwrite or define the data types. It takes a list of strings with column names that are numeric.\n",
    "\n",
    "numeric_imputation: str, default = ‘mean’\n",
    "Missing values in numeric features are imputed with ‘mean’ value of the feature in the training dataset. The other available option is ‘median’ or ‘zero’.\n",
    "\n",
    "numeric_iterative_imputer: str, default = ‘lightgbm’\n",
    "Estimator for iterative imputation of missing values in numeric features. Ignored when imputation_type is set to ‘simple’.\n",
    "\n",
    "date_features: list of str, default = None\n",
    "If the inferred data types are not correct or the silent param is set to True, date_features param can be used to overwrite or define the data types. It takes a list of strings with column names that are DateTime.\n",
    "\n",
    "ignore_features: list of str, default = None\n",
    "ignore_features param can be used to ignore features during model training. It takes a list of strings with column names that are to be ignored.\n",
    "\n",
    "normalize: bool, default = False\n",
    "When set to True, it transforms the numeric features by scaling them to a given range. Type of scaling is defined by the normalize_method parameter.\n",
    "\n",
    "normalize_method: str, default = ‘zscore’\n",
    "Defines the method for scaling. By default, normalize method is set to ‘zscore’ The standard zscore is calculated as z = (x - u) / s. Ignored when normalize is not True. The other options are:\n",
    "\n",
    "minmax: scales and translates each feature individually such that it is in the range of 0 - 1.\n",
    "\n",
    "maxabs: scales and translates each feature individually such that the maximal absolute value of each feature will be 1.0. It does not shift/center the data, and thus does not destroy any sparsity.\n",
    "\n",
    "robust: scales and translates each feature according to the Interquartile range. When the dataset contains outliers, robust scaler often gives better results.\n",
    "\n",
    "transformation: bool, default = False\n",
    "When set to True, it applies the power transform to make data more Gaussian-like. Type of transformation is defined by the transformation_method parameter.\n",
    "\n",
    "transformation_method: str, default = ‘yeo-johnson’\n",
    "Defines the method for transformation. By default, the transformation method is set to ‘yeo-johnson’. The other available option for transformation is ‘quantile’. Ignored when transformation is not True.\n",
    "\n",
    "handle_unknown_categorical: bool, default = True\n",
    "When set to True, unknown categorical levels in unseen data are replaced by the most or least frequent level as learned in the training dataset.\n",
    "\n",
    "unknown_categorical_method: str, default = ‘least_frequent’\n",
    "Method used to replace unknown categorical levels in unseen data. Method can be set to ‘least_frequent’ or ‘most_frequent’.\n",
    "\n",
    "pca: bool, default = False\n",
    "When set to True, dimensionality reduction is applied to project the data into a lower dimensional space using the method defined in pca_method parameter.\n",
    "\n",
    "pca_method: str, default = ‘linear’\n",
    "The ‘linear’ method performs uses Singular Value Decomposition. Other options are:\n",
    "\n",
    "kernel: dimensionality reduction through the use of RVF kernel.\n",
    "\n",
    "incremental: replacement for ‘linear’ pca when the dataset is too large.\n",
    "\n",
    "pca_components: int or float, default = None\n",
    "Number of components to keep. if pca_components is a float, it is treated as a target percentage for information retention. When pca_components is an integer it is treated as the number of features to be kept. pca_components must be less than the original number of features. Ignored when pca is not True.\n",
    "\n",
    "ignore_low_variance: bool, default = False\n",
    "When set to True, all categorical features with insignificant variances are removed from the data. The variance is calculated using the ratio of unique values to the number of samples, and the ratio of the most common value to the frequency of the second most common value.\n",
    "\n",
    "combine_rare_levels: bool, default = False\n",
    "When set to True, frequency percentile for levels in categorical features below a certain threshold is combined into a single level.\n",
    "\n",
    "rare_level_threshold: float, default = 0.1\n",
    "Percentile distribution below which rare categories are combined. Ignored when combine_rare_levels is not True.\n",
    "\n",
    "bin_numeric_features: list of str, default = None\n",
    "To convert numeric features into categorical, bin_numeric_features parameter can be used. It takes a list of strings with column names to be discretized. It does so by using ‘sturges’ rule to determine the number of clusters and then apply KMeans algorithm. Original values of the feature are then replaced by the cluster label.\n",
    "\n",
    "remove_outliers: bool, default = False\n",
    "When set to True, outliers from the training data are removed using the Singular Value Decomposition.\n",
    "\n",
    "outliers_threshold: float, default = 0.05\n",
    "The percentage outliers to be removed from the training dataset. Ignored when remove_outliers is not True.\n",
    "\n",
    "remove_multicollinearity: bool, default = False\n",
    "When set to True, features with the inter-correlations higher than the defined threshold are removed. When two features are highly correlated with each other, the feature that is less correlated with the target variable is removed. Only considers numeric features.\n",
    "\n",
    "multicollinearity_threshold: float, default = 0.9\n",
    "Threshold for correlated features. Ignored when remove_multicollinearity is not True.\n",
    "\n",
    "remove_perfect_collinearity: bool, default = True\n",
    "When set to True, perfect collinearity (features with correlation = 1) is removed from the dataset, when two features are 100% correlated, one of it is randomly removed from the dataset.\n",
    "\n",
    "create_clusters: bool, default = False\n",
    "When set to True, an additional feature is created in training dataset where each instance is assigned to a cluster. The number of clusters is determined by optimizing Calinski-Harabasz and Silhouette criterion.\n",
    "\n",
    "cluster_iter: int, default = 20\n",
    "Number of iterations for creating cluster. Each iteration represents cluster size. Ignored when create_clusters is not True.\n",
    "\n",
    "polynomial_features: bool, default = False\n",
    "When set to True, new features are derived using existing numeric features.\n",
    "\n",
    "polynomial_degree: int, default = 2\n",
    "Degree of polynomial features. For example, if an input sample is two dimensional and of the form [a, b], the polynomial features with degree = 2 are: [1, a, b, a^2, ab, b^2]. Ignored when polynomial_features is not True.\n",
    "\n",
    "trigonometry_features: bool, default = False\n",
    "When set to True, new features are derived using existing numeric features.\n",
    "\n",
    "polynomial_threshold: float, default = 0.1\n",
    "When polynomial_features or trigonometry_features is True, new features are derived from the existing numeric features. This may sometimes result in too large feature space. polynomial_threshold parameter can be used to deal with this problem. It does so by using combination of Random Forest, AdaBoost and Linear correlation. All derived features that falls within the percentile distribution are kept and rest of the features are removed.\n",
    "\n",
    "group_features: list or list of list, default = None\n",
    "When the dataset contains features with related characteristics, group_features parameter can be used for feature extraction. It takes a list of strings with column names that are related.\n",
    "\n",
    "group_names: list, default = None\n",
    "Group names to be used in naming new features. When the length of group_names does not match with the length of group_features, new features are named sequentially group_1, group_2, etc. It is ignored when group_features is None.\n",
    "\n",
    "feature_selection: bool, default = False\n",
    "When set to True, a subset of features are selected using a combination of various permutation importance techniques including Random Forest, Adaboost and Linear correlation with target variable. The size of the subset is dependent on the feature_selection_threshold parameter.\n",
    "\n",
    "feature_selection_threshold: float, default = 0.8\n",
    "Threshold value used for feature selection. When polynomial_features or feature_interaction is True, it is recommended to keep the threshold low to avoid large feature spaces. Setting a very low value may be efficient but could result in under-fitting.\n",
    "\n",
    "feature_selection_method: str, default = ‘classic’\n",
    "Algorithm for feature selection. ‘classic’ method uses permutation feature importance techniques. Other possible value is ‘boruta’ which uses boruta algorithm for feature selection.\n",
    "\n",
    "feature_interaction: bool, default = False\n",
    "When set to True, new features are created by interacting (a * b) all the numeric variables in the dataset. This feature is not scalable and may not work as expected on datasets with large feature space.\n",
    "\n",
    "feature_ratio: bool, default = False\n",
    "When set to True, new features are created by calculating the ratios (a / b) between all numeric variables in the dataset. This feature is not scalable and may not work as expected on datasets with large feature space.\n",
    "\n",
    "interaction_threshold: bool, default = 0.01\n",
    "Similar to polynomial_threshold, It is used to compress a sparse matrix of newly created features through interaction. Features whose importance based on the combination of Random Forest, AdaBoost and Linear correlation falls within the percentile of the defined threshold are kept in the dataset. Remaining features are dropped before further processing.\n",
    "\n",
    "fix_imbalance: bool, default = False\n",
    "When training dataset has unequal distribution of target class it can be balanced using this parameter. When set to True, SMOTE (Synthetic Minority Over-sampling Technique) is applied by default to create synthetic datapoints for minority class.\n",
    "\n",
    "fix_imbalance_method: obj, default = None\n",
    "When fix_imbalance is True, ‘imblearn’ compatible object with ‘fit_resample’ method can be passed. When set to None, ‘imblearn.over_sampling.SMOTE’ is used.\n",
    "\n",
    "data_split_shuffle: bool, default = True\n",
    "When set to False, prevents shuffling of rows during ‘train_test_split’.\n",
    "\n",
    "data_split_stratify: bool or list, default = False\n",
    "Controls stratification during ‘train_test_split’. When set to True, will stratify by target column. To stratify on any other columns, pass a list of column names. Ignored when data_split_shuffle is False.\n",
    "\n",
    "fold_strategy: str or sklearn CV generator object, default = ‘stratifiedkfold’\n",
    "Choice of cross validation strategy. Possible values are:\n",
    "\n",
    "‘kfold’\n",
    "\n",
    "‘stratifiedkfold’\n",
    "\n",
    "‘groupkfold’\n",
    "\n",
    "‘timeseries’\n",
    "\n",
    "a custom CV generator object compatible with scikit-learn.\n",
    "\n",
    "fold: int, default = 10\n",
    "Number of folds to be used in cross validation. Must be at least 2. This is a global setting that can be over-written at function level by using fold parameter. Ignored when fold_strategy is a custom object.\n",
    "\n",
    "fold_shuffle: bool, default = False\n",
    "Controls the shuffle parameter of CV. Only applicable when fold_strategy is ‘kfold’ or ‘stratifiedkfold’. Ignored when fold_strategy is a custom object.\n",
    "\n",
    "fold_groups: str or array-like, with shape (n_samples,), default = None\n",
    "Optional group labels when ‘GroupKFold’ is used for the cross validation. It takes an array with shape (n_samples, ) where n_samples is the number of rows in the training dataset. When string is passed, it is interpreted as the column name in the dataset containing group labels.\n",
    "\n",
    "n_jobs: int, default = -1\n",
    "The number of jobs to run in parallel (for functions that supports parallel processing) -1 means using all processors. To run all functions on single processor set n_jobs to None.\n",
    "\n",
    "use_gpu: bool or str, default = False\n",
    "When set to True, it will use GPU for training with algorithms that support it, and fall back to CPU if they are unavailable. When set to ‘force’, it will only use GPU-enabled algorithms and raise exceptions when they are unavailable. When False, all algorithms are trained using CPU only.\n",
    "\n",
    "GPU enabled algorithms:\n",
    "\n",
    "Extreme Gradient Boosting, requires no further installation\n",
    "\n",
    "CatBoost Classifier, requires no further installation (GPU is only enabled when data > 50,000 rows)\n",
    "\n",
    "Light Gradient Boosting Machine, requires GPU installation https://lightgbm.readthedocs.io/en/latest/GPU-Tutorial.html\n",
    "\n",
    "Logistic Regression, Ridge Classifier, Random Forest, K Neighbors Classifier, Support Vector Machine, requires cuML >= 0.15 https://github.com/rapidsai/cuml\n",
    "\n",
    "custom_pipeline: (str, transformer) or list of (str, transformer), default = None\n",
    "When passed, will append the custom transformers in the preprocessing pipeline and are applied on each CV fold separately and on the final fit. All the custom transformations are applied after ‘train_test_split’ and before pycaret’s internal transformations.\n",
    "\n",
    "html: bool, default = True\n",
    "When set to False, prevents runtime display of monitor. This must be set to False when the environment does not support IPython. For example, command line terminal, Databricks Notebook, Spyder and other similar IDEs.\n",
    "\n",
    "session_id: int, default = None\n",
    "Controls the randomness of experiment. It is equivalent to ‘random_state’ in scikit-learn. When None, a pseudo random number is generated. This can be used for later reproducibility of the entire experiment.\n",
    "\n",
    "log_experiment: bool, default = False\n",
    "When set to True, all metrics and parameters are logged on the MLFlow server.\n",
    "\n",
    "experiment_name: str, default = None\n",
    "Name of the experiment for logging. Ignored when log_experiment is not True.\n",
    "\n",
    "log_plots: bool or list, default = False\n",
    "When set to True, certain plots are logged automatically in the MLFlow server. To change the type of plots to be logged, pass a list containing plot IDs. Refer to documentation of plot_model. Ignored when log_experiment is not True.\n",
    "\n",
    "log_profile: bool, default = False\n",
    "When set to True, data profile is logged on the MLflow server as a html file. Ignored when log_experiment is not True.\n",
    "\n",
    "log_data: bool, default = False\n",
    "When set to True, dataset is logged on the MLflow server as a csv file. Ignored when log_experiment is not True.\n",
    "\n",
    "silent: bool, default = False\n",
    "Controls the confirmation input of data types when setup is executed. When executing in completely automated mode or on a remote kernel, this must be True.\n",
    "\n",
    "verbose: bool, default = True\n",
    "When set to False, Information grid is not printed.\n",
    "\n",
    "profile: bool, default = False\n",
    "When set to True, an interactive EDA report is displayed.\n",
    "\n",
    "profile_kwargs: dict, default = {} (empty dict)\n",
    "Dictionary of arguments passed to the ProfileReport method used to create the EDA report. Ignored if profile is False.\n",
    "\n",
    "Returns\n",
    "Global variables that can be changed using the set_config function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification compare models function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function trains and evaluates performance of all estimators available in the model library using cross validation. The output of this function is a score grid with average cross validated scores. Metrics evaluated during CV can be accessed using the get_metrics function. Custom metrics can be added or removed using add_metric and remove_metric function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.datasets import get_data\n",
    "juice = get_data('juice')\n",
    "from pycaret.classification import *\n",
    "exp_name = setup(data = juice,  target = 'Purchase')\n",
    "best_model = compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycaret.classification.compare_models(include: Optional[List[Union[str, Any]]] = None, \n",
    "                                      exclude: Optional[List[str]] = None, \n",
    "                                      fold: Optional[Union[int, Any]] = None, \n",
    "                                      round: int = 4, \n",
    "                                      cross_validation: bool = True, \n",
    "                                      sort: str = 'Accuracy', n_select: int = 1, \n",
    "                                      budget_time: Optional[float] = None, turbo: bool = True, errors: str = 'ignore', \n",
    "                                      fit_kwargs: Optional[dict] = None, groups: Optional[Union[str, Any]] = None, \n",
    "                                      probability_threshold: Optional[float] = None, verbose: bool = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "include: list of str or scikit-learn compatible object, default = None\n",
    "To train and evaluate select models, list containing model ID or scikit-learn compatible object can be passed in include param. To see a list of all models available in the model library use the models function.\n",
    "\n",
    "exclude: list of str, default = None\n",
    "To omit certain models from training and evaluation, pass a list containing model id in the exclude parameter. To see a list of all models available in the model library use the models function.\n",
    "\n",
    "fold: int or scikit-learn compatible CV generator, default = None\n",
    "Controls cross-validation. If None, the CV generator in the fold_strategy parameter of the setup function is used. When an integer is passed, it is interpreted as the ‘n_splits’ parameter of the CV generator in the setup function.\n",
    "\n",
    "round: int, default = 4\n",
    "Number of decimal places the metrics in the score grid will be rounded to.\n",
    "\n",
    "cross_validation: bool, default = True\n",
    "When set to False, metrics are evaluated on holdout set. fold param is ignored when cross_validation is set to False.\n",
    "\n",
    "sort: str, default = ‘Accuracy’\n",
    "The sort order of the score grid. It also accepts custom metrics that are added through the add_metric function.\n",
    "\n",
    "n_select: int, default = 1\n",
    "Number of top_n models to return. For example, to select top 3 models use n_select = 3.\n",
    "\n",
    "budget_time: int or float, default = None\n",
    "If not None, will terminate execution of the function after budget_time minutes have passed and return results up to that point.\n",
    "\n",
    "turbo: bool, default = True\n",
    "When set to True, it excludes estimators with longer training times. To see which algorithms are excluded use the models function.\n",
    "\n",
    "errors: str, default = ‘ignore’\n",
    "When set to ‘ignore’, will skip the model with exceptions and continue. If ‘raise’, will break the function when exceptions are raised.\n",
    "\n",
    "fit_kwargs: dict, default = {} (empty dict)\n",
    "Dictionary of arguments passed to the fit method of the model.\n",
    "\n",
    "groups: str or array-like, with shape (n_samples,), default = None\n",
    "Optional group labels when ‘GroupKFold’ is used for the cross validation. It takes an array with shape (n_samples, ) where n_samples is the number of rows in the training dataset. When string is passed, it is interpreted as the column name in the dataset containing group labels.\n",
    "\n",
    "probability_threshold: float, default = None\n",
    "Threshold for converting predicted probability to class label. It defaults to 0.5 for all classifiers unless explicitly defined in this parameter. Only applicable for binary classification.\n",
    "\n",
    "verbose: bool, default = True\n",
    "Score grid is not printed when verbose is set to False.\n",
    "\n",
    "Returns\n",
    "Trained model or list of trained models, depending on the n_select param."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification create model function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function trains and evaluates the performance of a given estimator using cross validation. The output of this function is a score grid with CV scores by fold. Metrics evaluated during CV can be accessed using the get_metrics function. Custom metrics can be added or removed using add_metric and remove_metric function. All the available models can be accessed using the models function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.datasets import get_data\n",
    "juice = get_data('juice')\n",
    "from pycaret.classification import *\n",
    "exp_name = setup(data = juice,  target = 'Purchase')\n",
    "lr = create_model('lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycaret.classification.create_model(estimator: Union[str, Any], \n",
    "                                    fold: Optional[Union[int, Any]] = None, round: int = 4, \n",
    "                                    cross_validation: bool = True, fit_kwargs: Optional[dict] = None, \n",
    "                                    groups: Optional[Union[str, Any]] = None, \n",
    "                                    probability_threshold: Optional[float] = None, \n",
    "                                    verbose: bool = True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fold: int or scikit-learn compatible CV generator, default = None\n",
    "Controls cross-validation. If None, the CV generator in the fold_strategy parameter of the setup function is used. When an integer is passed, it is interpreted as the ‘n_splits’ parameter of the CV generator in the setup function.\n",
    "\n",
    "round: int, default = 4\n",
    "Number of decimal places the metrics in the score grid will be rounded to.\n",
    "\n",
    "cross_validation: bool, default = True\n",
    "When set to False, metrics are evaluated on holdout set. fold param is ignored when cross_validation is set to False.\n",
    "\n",
    "fit_kwargs: dict, default = {} (empty dict)\n",
    "Dictionary of arguments passed to the fit method of the model.\n",
    "\n",
    "groups: str or array-like, with shape (n_samples,), default = None\n",
    "Optional group labels when GroupKFold is used for the cross validation. It takes an array with shape (n_samples, ) where n_samples is the number of rows in training dataset. When string is passed, it is interpreted as the column name in the dataset containing group labels.\n",
    "\n",
    "probability_threshold: float, default = None\n",
    "Threshold for converting predicted probability to class label. It defaults to 0.5 for all classifiers unless explicitly defined in this parameter. Only applicable for binary classification.\n",
    "\n",
    "verbose: bool, default = True\n",
    "Score grid is not printed when verbose is set to False.\n",
    "\n",
    "**kwargs:\n",
    "Additional keyword arguments to pass to the estimator.\n",
    "\n",
    "Returns\n",
    "Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**classification tune_model function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function tunes the hyperparameters of a given estimator. The output of this function is a score grid with CV scores by fold of the best selected model based on optimize parameter. Metrics evaluated during CV can be accessed using the get_metrics function. Custom metrics can be added or removed using add_metric and remove_metric function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.datasets import get_data\n",
    "juice = get_data('juice')\n",
    "from pycaret.classification import *\n",
    "exp_name = setup(data = juice,  target = 'Purchase')\n",
    "lr = create_model('lr')\n",
    "tuned_lr = tune_model(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycaret.classification.tune_model(estimator, \n",
    "                                  fold: Optional[Union[int, Any]] = None, \n",
    "                                  round: int = 4, \n",
    "                                  n_iter: int = 10, \n",
    "                                  custom_grid: Optional[Union[Dict[str, list], Any]] = None, \n",
    "                                  optimize: str = 'Accuracy', \n",
    "                                  custom_scorer=None, search_library: str = 'scikit-learn', \n",
    "                                  search_algorithm: Optional[str] = None, \n",
    "                                  early_stopping: Any = False, \n",
    "                                  early_stopping_max_iters: int = 10, \n",
    "                                  choose_better: bool = False, \n",
    "                                  fit_kwargs: Optional[dict] = None, \n",
    "                                  groups: Optional[Union[str, Any]] = None, \n",
    "                                  return_tuner: bool = False, \n",
    "                                  verbose: bool = True, \n",
    "                                  tuner_verbose: Union[int, bool] = True, \n",
    "                                  **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estimator: scikit-learn compatible object\n",
    "Trained model object\n",
    "\n",
    "fold: int or scikit-learn compatible CV generator, default = None\n",
    "Controls cross-validation. If None, the CV generator in the fold_strategy parameter of the setup function is used. When an integer is passed, it is interpreted as the ‘n_splits’ parameter of the CV generator in the setup function.\n",
    "\n",
    "round: int, default = 4\n",
    "Number of decimal places the metrics in the score grid will be rounded to.\n",
    "\n",
    "n_iter: int, default = 10\n",
    "Number of iterations in the grid search. Increasing ‘n_iter’ may improve model performance but also increases the training time.\n",
    "\n",
    "custom_grid: dictionary, default = None\n",
    "To define custom search space for hyperparameters, pass a dictionary with parameter name and values to be iterated. Custom grids must be in a format supported by the defined search_library.\n",
    "\n",
    "optimize: str, default = ‘Accuracy’\n",
    "Metric name to be evaluated for hyperparameter tuning. It also accepts custom metrics that are added through the add_metric function.\n",
    "\n",
    "custom_scorer: object, default = None\n",
    "custom scoring strategy can be passed to tune hyperparameters of the model. It must be created using sklearn.make_scorer. It is equivalent of adding custom metric using the add_metric function and passing the name of the custom metric in the optimize parameter. Will be deprecated in future.\n",
    "\n",
    "search_library: str, default = ‘scikit-learn’\n",
    "The search library used for tuning hyperparameters. Possible values:\n",
    "\n",
    "‘scikit-learn’ - default, requires no further installation\n",
    "https://github.com/scikit-learn/scikit-learn\n",
    "\n",
    "‘scikit-optimize’ - pip install scikit-optimize\n",
    "https://scikit-optimize.github.io/stable/\n",
    "\n",
    "‘tune-sklearn’ - pip install tune-sklearn ray[tune]\n",
    "https://github.com/ray-project/tune-sklearn\n",
    "\n",
    "‘optuna’ - pip install optuna\n",
    "https://optuna.org/\n",
    "\n",
    "search_algorithm: str, default = None\n",
    "The search algorithm depends on the search_library parameter. Some search algorithms require additional libraries to be installed. If None, will use search library-specific default algorithm.\n",
    "\n",
    "‘scikit-learn’ possible values:\n",
    "‘random’ : random grid search (default)\n",
    "\n",
    "‘grid’ : grid search\n",
    "\n",
    "‘scikit-optimize’ possible values:\n",
    "‘bayesian’ : Bayesian search (default)\n",
    "\n",
    "‘tune-sklearn’ possible values:\n",
    "‘random’ : random grid search (default)\n",
    "\n",
    "‘grid’ : grid search\n",
    "\n",
    "‘bayesian’ : pip install scikit-optimize\n",
    "\n",
    "‘hyperopt’ : pip install hyperopt\n",
    "\n",
    "‘optuna’ : pip install optuna\n",
    "\n",
    "‘bohb’ : pip install hpbandster ConfigSpace\n",
    "\n",
    "‘optuna’ possible values:\n",
    "‘random’ : randomized search\n",
    "\n",
    "‘tpe’ : Tree-structured Parzen Estimator search (default)\n",
    "\n",
    "early_stopping: bool or str or object, default = False\n",
    "Use early stopping to stop fitting to a hyperparameter configuration if it performs poorly. Ignored when search_library is scikit-learn, or if the estimator does not have ‘partial_fit’ attribute. If False or None, early stopping will not be used. Can be either an object accepted by the search library or one of the following:\n",
    "\n",
    "‘asha’ for Asynchronous Successive Halving Algorithm\n",
    "\n",
    "‘hyperband’ for Hyperband\n",
    "\n",
    "‘median’ for Median Stopping Rule\n",
    "\n",
    "If False or None, early stopping will not be used.\n",
    "\n",
    "early_stopping_max_iters: int, default = 10\n",
    "Maximum number of epochs to run for each sampled configuration. Ignored if early_stopping is False or None.\n",
    "\n",
    "choose_better: bool, default = False\n",
    "When set to True, the returned object is always better performing. The metric used for comparison is defined by the optimize parameter.\n",
    "\n",
    "fit_kwargs: dict, default = {} (empty dict)\n",
    "Dictionary of arguments passed to the fit method of the tuner.\n",
    "\n",
    "groups: str or array-like, with shape (n_samples,), default = None\n",
    "Optional group labels when GroupKFold is used for the cross validation. It takes an array with shape (n_samples, ) where n_samples is the number of rows in training dataset. When string is passed, it is interpreted as the column name in the dataset containing group labels.\n",
    "\n",
    "return_tuner: bool, default = False\n",
    "When set to True, will return a tuple of (model, tuner_object).\n",
    "\n",
    "verbose: bool, default = True\n",
    "Score grid is not printed when verbose is set to False.\n",
    "\n",
    "tuner_verbose: bool or in, default = True\n",
    "If True or above 0, will print messages from the tuner. Higher values print more messages. Ignored when verbose param is False.\n",
    "\n",
    "**kwargs:\n",
    "Additional keyword arguments to pass to the optimizer.\n",
    "\n",
    "Returns\n",
    "Trained Model and Optional Tuner Object when return_tuner is True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**classification ensemble_model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function ensembles a given estimator. The output of this function is a score grid with CV scores by fold. Metrics evaluated during CV can be accessed using the get_metrics function. Custom metrics can be added or removed using add_metric and remove_metric function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.datasets import get_data\n",
    "juice = get_data('juice')\n",
    "from pycaret.classification import *\n",
    "exp_name = setup(data = juice,  target = 'Purchase')\n",
    "dt = create_model('dt')\n",
    "bagged_dt = ensemble_model(dt, method = 'Bagging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycaret.classification.ensemble_model(estimator, method: str = 'Bagging', \n",
    "                                      fold: Optional[Union[int, Any]] = None, \n",
    "                                      n_estimators: int = 10, round: int = 4, \n",
    "                                      choose_better: bool = False, optimize: str = 'Accuracy', \n",
    "                                      fit_kwargs: Optional[dict] = None, \n",
    "                                      groups: Optional[Union[str, Any]] = None, \n",
    "                                      probability_threshold: Optional[float] = None, \n",
    "                                      verbose: bool = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estimator: scikit-learn compatible object\n",
    "Trained model object\n",
    "\n",
    "method: str, default = ‘Bagging’\n",
    "Method for ensembling base estimator. It can be ‘Bagging’ or ‘Boosting’.\n",
    "\n",
    "fold: int or scikit-learn compatible CV generator, default = None\n",
    "Controls cross-validation. If None, the CV generator in the fold_strategy parameter of the setup function is used. When an integer is passed, it is interpreted as the ‘n_splits’ parameter of the CV generator in the setup function.\n",
    "\n",
    "n_estimators: int, default = 10\n",
    "The number of base estimators in the ensemble. In case of perfect fit, the learning procedure is stopped early.\n",
    "\n",
    "round: int, default = 4\n",
    "Number of decimal places the metrics in the score grid will be rounded to.\n",
    "\n",
    "choose_better: bool, default = False\n",
    "When set to True, the returned object is always better performing. The metric used for comparison is defined by the optimize parameter.\n",
    "\n",
    "optimize: str, default = ‘Accuracy’\n",
    "Metric to compare for model selection when choose_better is True.\n",
    "\n",
    "fit_kwargs: dict, default = {} (empty dict)\n",
    "Dictionary of arguments passed to the fit method of the model.\n",
    "\n",
    "groups: str or array-like, with shape (n_samples,), default = None\n",
    "Optional group labels when GroupKFold is used for the cross validation. It takes an array with shape (n_samples, ) where n_samples is the number of rows in training dataset. When string is passed, it is interpreted as the column name in the dataset containing group labels.\n",
    "\n",
    "probability_threshold: float, default = None\n",
    "Threshold for converting predicted probability to class label. It defaults to 0.5 for all classifiers unless explicitly defined in this parameter. Only applicable for binary classification.\n",
    "\n",
    "verbose: bool, default = True\n",
    "Score grid is not printed when verbose is set to False.\n",
    "\n",
    "Returns\n",
    "Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**classification blend_models functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function trains a Soft Voting / Majority Rule classifier for select models passed in the estimator_list param. The output of this function is a score grid with CV scores by fold. Metrics evaluated during CV can be accessed using the get_metrics function. Custom metrics can be added or removed using add_metric and remove_metric function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.datasets import get_data\n",
    "juice = get_data('juice')\n",
    "from pycaret.classification import *\n",
    "exp_name = setup(data = juice,  target = 'Purchase')\n",
    "top3 = compare_models(n_select = 3)\n",
    "blender = blend_models(top3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycaret.classification.blend_models(estimator_list: list, \n",
    "                                    fold: Optional[Union[int, Any]] = None, round: int = 4, \n",
    "                                    choose_better: bool = False, optimize: str = 'Accuracy', \n",
    "                                    method: str = 'auto', \n",
    "                                    weights: Optional[List[float]] = None, \n",
    "                                    fit_kwargs: Optional[dict] = None, \n",
    "                                    groups: Optional[Union[str, Any]] = None, \n",
    "                                    probability_threshold: Optional[float] = None, verbose: bool = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estimator_list: list of scikit-learn compatible objects\n",
    "List of trained model objects\n",
    "\n",
    "fold: int or scikit-learn compatible CV generator, default = None\n",
    "Controls cross-validation. If None, the CV generator in the fold_strategy parameter of the setup function is used. When an integer is passed, it is interpreted as the ‘n_splits’ parameter of the CV generator in the setup function.\n",
    "\n",
    "round: int, default = 4\n",
    "Number of decimal places the metrics in the score grid will be rounded to.\n",
    "\n",
    "choose_better: bool, default = False\n",
    "When set to True, the returned object is always better performing. The metric used for comparison is defined by the optimize parameter.\n",
    "\n",
    "optimize: str, default = ‘Accuracy’\n",
    "Metric to compare for model selection when choose_better is True.\n",
    "\n",
    "method: str, default = ‘auto’\n",
    "‘hard’ uses predicted class labels for majority rule voting. ‘soft’, predicts the class label based on the argmax of the sums of the predicted probabilities, which is recommended for an ensemble of well-calibrated classifiers. Default value, ‘auto’, will try to use ‘soft’ and fall back to ‘hard’ if the former is not supported.\n",
    "\n",
    "weights: list, default = None\n",
    "Sequence of weights (float or int) to weight the occurrences of predicted class labels (hard voting) or class probabilities before averaging (soft voting). Uses uniform weights when None.\n",
    "\n",
    "fit_kwargs: dict, default = {} (empty dict)\n",
    "Dictionary of arguments passed to the fit method of the model.\n",
    "\n",
    "groups: str or array-like, with shape (n_samples,), default = None\n",
    "Optional group labels when GroupKFold is used for the cross validation. It takes an array with shape (n_samples, ) where n_samples is the number of rows in training dataset. When string is passed, it is interpreted as the column name in the dataset containing group labels.\n",
    "\n",
    "probability_threshold: float, default = None\n",
    "Threshold for converting predicted probability to class label. It defaults to 0.5 for all classifiers unless explicitly defined in this parameter. Only applicable for binary classification.\n",
    "\n",
    "verbose: bool, default = True\n",
    "Score grid is not printed when verbose is set to False.\n",
    "\n",
    "Returns\n",
    "Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**classification stack_models functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function trains a meta model over select estimators passed in the estimator_list parameter. The output of this function is a score grid with CV scores by fold. Metrics evaluated during CV can be accessed using the get_metrics function. Custom metrics can be added or removed using add_metric and remove_metric function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.datasets import get_data\n",
    "juice = get_data('juice')\n",
    "from pycaret.classification import *\n",
    "exp_name = setup(data = juice,  target = 'Purchase')\n",
    "top3 = compare_models(n_select = 3)\n",
    "stacker = stack_models(top3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycaret.classification.stack_models(estimator_list: list, \n",
    "                                    meta_model=None, meta_model_fold: Optional[Union[int, Any]] = 5, \n",
    "                                    fold: Optional[Union[int, Any]] = None, round: int = 4, \n",
    "                                    method: str = 'auto', \n",
    "                                    restack: bool = True, \n",
    "                                    choose_better: bool = False, \n",
    "                                    optimize: str = 'Accuracy', \n",
    "                                    fit_kwargs: Optional[dict] = None, groups: Optional[Union[str, Any]] = None, \n",
    "                                    probability_threshold: Optional[float] = None, \n",
    "                                    verbose: bool = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estimator_list: list of scikit-learn compatible objects\n",
    "List of trained model objects\n",
    "\n",
    "meta_model: scikit-learn compatible object, default = None\n",
    "When None, Logistic Regression is trained as a meta model.\n",
    "\n",
    "meta_model_fold: integer or scikit-learn compatible CV generator, default = 5\n",
    "Controls internal cross-validation. Can be an integer or a scikit-learn CV generator. If set to an integer, will use (Stratifed)KFold CV with that many folds. See scikit-learn documentation on Stacking for more details.\n",
    "\n",
    "fold: int or scikit-learn compatible CV generator, default = None\n",
    "Controls cross-validation. If None, the CV generator in the fold_strategy parameter of the setup function is used. When an integer is passed, it is interpreted as the ‘n_splits’ parameter of the CV generator in the setup function.\n",
    "\n",
    "round: int, default = 4\n",
    "Number of decimal places the metrics in the score grid will be rounded to.\n",
    "\n",
    "method: str, default = ‘auto’\n",
    "When set to ‘auto’, it will invoke, for each estimator, ‘predict_proba’, ‘decision_function’ or ‘predict’ in that order. Other, manually pass one of the value from ‘predict_proba’, ‘decision_function’ or ‘predict’.\n",
    "\n",
    "restack: bool, default = True\n",
    "When set to False, only the predictions of estimators will be used as training data for the meta_model.\n",
    "\n",
    "choose_better: bool, default = False\n",
    "When set to True, the returned object is always better performing. The metric used for comparison is defined by the optimize parameter.\n",
    "\n",
    "optimize: str, default = ‘Accuracy’\n",
    "Metric to compare for model selection when choose_better is True.\n",
    "\n",
    "fit_kwargs: dict, default = {} (empty dict)\n",
    "Dictionary of arguments passed to the fit method of the model.\n",
    "\n",
    "groups: str or array-like, with shape (n_samples,), default = None\n",
    "Optional group labels when GroupKFold is used for the cross validation. It takes an array with shape (n_samples, ) where n_samples is the number of rows in training dataset. When string is passed, it is interpreted as the column name in the dataset containing group labels.\n",
    "\n",
    "probability_threshold: float, default = None\n",
    "Threshold for converting predicted probability to class label. It defaults to 0.5 for all classifiers unless explicitly defined in this parameter. Only applicable for binary classification.\n",
    "\n",
    "verbose: bool, default = True\n",
    "Score grid is not printed when verbose is set to False.\n",
    "\n",
    "Returns\n",
    "Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**classification.plot_model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function analyzes the performance of a trained model on holdout set. It may require re-training the model in certain cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.datasets import get_data\n",
    "juice = get_data('juice')\n",
    "from pycaret.classification import *\n",
    "exp_name = setup(data = juice,  target = 'Purchase')\n",
    "lr = create_model('lr')\n",
    "plot_model(lr, plot = 'auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(estimator, plot: str = 'auc', \n",
    " scale: float = 1, \n",
    " save: bool = False, \n",
    " fold: Optional[Union[int, Any]] = None, \n",
    " fit_kwargs: Optional[dict] = None, \n",
    " plot_kwargs: Optional[dict] = None, groups: Optional[Union[str, Any]] = None, \n",
    " use_train_data: bool = False, \n",
    " verbose: bool = True, \n",
    " display_format: Optional[str] = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estimator: scikit-learn compatible object\n",
    "Trained model object\n",
    "\n",
    "plot: str, default = ‘auc’\n",
    "List of available plots (ID - Name):\n",
    "\n",
    "‘auc’ - Area Under the Curve\n",
    "\n",
    "‘threshold’ - Discrimination Threshold\n",
    "\n",
    "‘pr’ - Precision Recall Curve\n",
    "\n",
    "‘confusion_matrix’ - Confusion Matrix\n",
    "\n",
    "‘error’ - Class Prediction Error\n",
    "\n",
    "‘class_report’ - Classification Report\n",
    "\n",
    "‘boundary’ - Decision Boundary\n",
    "\n",
    "‘rfe’ - Recursive Feature Selection\n",
    "\n",
    "‘learning’ - Learning Curve\n",
    "\n",
    "‘manifold’ - Manifold Learning\n",
    "\n",
    "‘calibration’ - Calibration Curve\n",
    "\n",
    "‘vc’ - Validation Curve\n",
    "\n",
    "‘dimension’ - Dimension Learning\n",
    "\n",
    "‘feature’ - Feature Importance\n",
    "\n",
    "‘feature_all’ - Feature Importance (All)\n",
    "\n",
    "‘parameter’ - Model Hyperparameter\n",
    "\n",
    "‘lift’ - Lift Curve\n",
    "\n",
    "‘gain’ - Gain Chart\n",
    "\n",
    "‘tree’ - Decision Tree\n",
    "\n",
    "‘ks’ - KS Statistic Plot\n",
    "\n",
    "scale: float, default = 1\n",
    "The resolution scale of the figure.\n",
    "\n",
    "save: bool, default = False\n",
    "When set to True, plot is saved in the current working directory.\n",
    "\n",
    "fold: int or scikit-learn compatible CV generator, default = None\n",
    "Controls cross-validation. If None, the CV generator in the fold_strategy parameter of the setup function is used. When an integer is passed, it is interpreted as the ‘n_splits’ parameter of the CV generator in the setup function.\n",
    "\n",
    "fit_kwargs: dict, default = {} (empty dict)\n",
    "Dictionary of arguments passed to the fit method of the model.\n",
    "\n",
    "plot_kwargs: dict, default = {} (empty dict)\n",
    "Dictionary of arguments passed to the visualizer class.\n",
    "\n",
    "groups: str or array-like, with shape (n_samples,), default = None\n",
    "Optional group labels when GroupKFold is used for the cross validation. It takes an array with shape (n_samples, ) where n_samples is the number of rows in training dataset. When string is passed, it is interpreted as the column name in the dataset containing group labels.\n",
    "\n",
    "use_train_data: bool, default = False\n",
    "When set to true, train data will be used for plots, instead of test data.\n",
    "\n",
    "verbose: bool, default = True\n",
    "When set to False, progress bar is not displayed.\n",
    "\n",
    "display_format: str, default = None\n",
    "To display plots in Streamlit (https://www.streamlit.io/), set this to ‘streamlit’. Currently, not all plots are supported.\n",
    "\n",
    "Returns\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**classification evaluate_model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function displays a user interface for analyzing performance of a trained model. It calls the plot_model function internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycaret.classification.evaluate_model(estimator, \n",
    "                                      fold: Optional[Union[int, Any]] = None, \n",
    "                                      fit_kwargs: Optional[dict] = None, \n",
    "                                      plot_kwargs: Optional[dict] = None, \n",
    "                                      groups: Optional[Union[str, Any]] = None, \n",
    "                                      use_train_data: bool = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.datasets import get_data\n",
    "juice = get_data('juice')\n",
    "from pycaret.classification import *\n",
    "exp_name = setup(data = juice,  target = 'Purchase')\n",
    "lr = create_model('lr')\n",
    "evaluate_model(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stimator: scikit-learn compatible object\n",
    "Trained model object\n",
    "\n",
    "fold: int or scikit-learn compatible CV generator, default = None\n",
    "Controls cross-validation. If None, the CV generator in the fold_strategy parameter of the setup function is used. When an integer is passed, it is interpreted as the ‘n_splits’ parameter of the CV generator in the setup function.\n",
    "\n",
    "fit_kwargs: dict, default = {} (empty dict)\n",
    "Dictionary of arguments passed to the fit method of the model.\n",
    "\n",
    "plot_kwargs: dict, default = {} (empty dict)\n",
    "Dictionary of arguments passed to the visualizer class.\n",
    "\n",
    "groups: str or array-like, with shape (n_samples,), default = None\n",
    "Optional group labels when GroupKFold is used for the cross validation. It takes an array with shape (n_samples, ) where n_samples is the number of rows in training dataset. When string is passed, it is interpreted as the column name in the dataset containing group labels.\n",
    "\n",
    "use_train_data: bool, default = False\n",
    "When set to true, train data will be used for plots, instead of test data.\n",
    "\n",
    "Returns\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**classification interpret_model function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function analyzes the predictions generated from a trained model. Most plots in this function are implemented based on the SHAP (SHapley Additive exPlanations). For more info on this, please see https://shap.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.datasets import get_data\n",
    "juice = get_data('juice')\n",
    "from pycaret.classification import *\n",
    "exp_name = setup(data = juice,  target = 'Purchase')\n",
    "xgboost = create_model('xgboost')\n",
    "interpret_model(xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycaret.classification.interpret_model(estimator, plot: str = 'summary', \n",
    "                                       feature: Optional[str] = None, \n",
    "                                       observation: Optional[int] = None, \n",
    "                                       use_train_data: bool = False, \n",
    "                                       X_new_sample: Optional[pandas.core.frame.DataFrame] = None, \n",
    "                                       y_new_sample: Optional[pandas.core.frame.DataFrame] = None, \n",
    "                                       save: bool = False, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estimator: scikit-learn compatible object\n",
    "Trained model object\n",
    "\n",
    "plotstr, default = ‘summary’\n",
    "Abbreviation of type of plot. The current list of plots supported are (Plot - Name):\n",
    "\n",
    "‘summary’ - Summary Plot using SHAP\n",
    "\n",
    "‘correlation’ - Dependence Plot using SHAP\n",
    "\n",
    "‘reason’ - Force Plot using SHAP\n",
    "\n",
    "‘pdp’ - Partial Dependence Plot\n",
    "\n",
    "‘msa’ - Morris Sensitivity Analysis\n",
    "\n",
    "‘pfi’ - Permutation Feature Importance\n",
    "\n",
    "feature: str, default = None\n",
    "This parameter is only needed when plot = ‘correlation’ or ‘pdp’. By default feature is set to None which means the first column of the dataset will be used as a variable. A feature parameter must be passed to change this.\n",
    "\n",
    "observation: integer, default = None\n",
    "This parameter only comes into effect when plot is set to ‘reason’. If no observation number is provided, it will return an analysis of all observations with the option to select the feature on x and y axes through drop down interactivity. For analysis at the sample level, an observation parameter must be passed with the index value of the observation in test / hold-out set.\n",
    "\n",
    "use_train_data: bool, default = False\n",
    "When set to true, train data will be used for plots, instead of test data.\n",
    "\n",
    "X_new_sample: pd.DataFrame, default = None\n",
    "Row from an out-of-sample dataframe (neither train nor test data) to be plotted. The sample must have the same columns as the raw input data, and it is transformed by the preprocessing pipeline automatically before plotting.\n",
    "\n",
    "y_new_sample: pd.DataFrame, default = None\n",
    "Row from an out-of-sample dataframe (neither train nor test data) to be plotted. The sample must have the same columns as the raw input label data, and it is transformed by the preprocessing pipeline automatically before plotting.\n",
    "\n",
    "save: bool, default = False\n",
    "When set to True, Plot is saved as a ‘png’ file in current working directory.\n",
    "\n",
    "**kwargs:\n",
    "Additional keyword arguments to pass to the plot.\n",
    "\n",
    "Returns\n",
    "None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**classification calibrate_model function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function calibrates the probability of a given estimator using isotonic or logistic regression. The output of this function is a score grid with CV scores by fold. Metrics evaluated during CV can be accessed using the get_metrics function. Custom metrics can be added or removed using add_metric and remove_metric function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.datasets import get_data\n",
    "juice = get_data('juice')\n",
    "from pycaret.classification import *\n",
    "exp_name = setup(data = juice,  target = 'Purchase')\n",
    "dt = create_model('dt')\n",
    "calibrated_dt = calibrate_model(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycaret.classification.calibrate_model(estimator, method: str = 'sigmoid', \n",
    "                                       calibrate_fold: Optional[Union[int, Any]] = 5, \n",
    "                                       fold: Optional[Union[int, Any]] = None, round: int = 4, \n",
    "                                       fit_kwargs: Optional[dict] = None, \n",
    "                                       groups: Optional[Union[str, Any]] = None, \n",
    "                                       verbose: bool = True)→ Any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estimator: scikit-learn compatible object\n",
    "Trained model object\n",
    "\n",
    "method: str, default = ‘sigmoid’\n",
    "The method to use for calibration. Can be ‘sigmoid’ which corresponds to Platt’s method or ‘isotonic’ which is a non-parametric approach.\n",
    "\n",
    "calibrate_fold: integer or scikit-learn compatible CV generator, default = 5\n",
    "Controls internal cross-validation. Can be an integer or a scikit-learn CV generator. If set to an integer, will use (Stratifed)KFold CV with that many folds. See scikit-learn documentation on Stacking for more details.\n",
    "\n",
    "fold: int or scikit-learn compatible CV generator, default = None\n",
    "Controls cross-validation. If None, the CV generator in the fold_strategy parameter of the setup function is used. When an integer is passed, it is interpreted as the ‘n_splits’ parameter of the CV generator in the setup function.\n",
    "\n",
    "round: int, default = 4\n",
    "Number of decimal places the metrics in the score grid will be rounded to.\n",
    "\n",
    "fit_kwargs: dict, default = {} (empty dict)\n",
    "Dictionary of arguments passed to the fit method of the model.\n",
    "\n",
    "groups: str or array-like, with shape (n_samples,), default = None\n",
    "Optional group labels when GroupKFold is used for the cross validation. It takes an array with shape (n_samples, ) where n_samples is the number of rows in training dataset. When string is passed, it is interpreted as the column name in the dataset containing group labels.\n",
    "\n",
    "verbose: bool, default = True\n",
    "Score grid is not printed when verbose is set to False.\n",
    "\n",
    "Returns\n",
    "Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**classification optimize_threshold function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function optimizes probability threshold for a given estimator using custom cost function. The function displays a plot of optimized cost as a function of probability threshold between 0.0 to 1.0 and returns the optimized threshold value as a numpy float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.datasets import get_data\n",
    "juice = get_data('juice')\n",
    "from pycaret.classification import *\n",
    "exp_name = setup(data = juice,  target = 'Purchase')\n",
    "lr = create_model('lr')\n",
    "optimize_threshold(lr, true_negative = 10, false_negative = -100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycaret.classification.optimize_threshold(estimator, \n",
    "                                          true_positive: int = 0, \n",
    "                                          true_negative: int = 0, \n",
    "                                          false_positive: int = 0, \n",
    "                                          false_negative: int = 0, \n",
    "                                          grid_interval: float = 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estimator: scikit-learn compatible object\n",
    "Trained model object\n",
    "\n",
    "true_positive: int, default = 0\n",
    "Cost function or returns for true positive.\n",
    "\n",
    "true_negative: int, default = 0\n",
    "Cost function or returns for true negative.\n",
    "\n",
    "false_positive: int, default = 0\n",
    "Cost function or returns for false positive.\n",
    "\n",
    "false_negative: int, default = 0\n",
    "Cost function or returns for false negative.\n",
    "\n",
    "grid_interval: float, default = 0.0001\n",
    "Grid inerval for threshold grid search. Iteration count = 1.0/grid_interval. Default 10000 iterations.\n",
    "\n",
    "Returns\n",
    "numpy.float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**classification predict_model function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function predicts Label and Score (probability of predicted class) using a trained model. When data is None, it predicts label and score on the holdout set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.datasets import get_data\n",
    "juice = get_data('juice')\n",
    "from pycaret.classification import *\n",
    "exp_name = setup(data = juice,  target = 'Purchase')\n",
    "lr = create_model('lr')\n",
    "pred_holdout = predict_model(lr)\n",
    "pred_unseen = predict_model(lr, data = unseen_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycaret.classification.predict_model(estimator, data: Optional[pandas.core.frame.DataFrame] = None, \n",
    "                                     probability_threshold: Optional[float] = None, \n",
    "                                     encoded_labels: bool = False, raw_score: bool = False, \n",
    "                                     drift_report: bool = False, round: int = 4, \n",
    "                                     verbose: bool = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estimator: scikit-learn compatible object\n",
    "Trained model object\n",
    "\n",
    "data: pandas.DataFrame\n",
    "Shape (n_samples, n_features). All features used during training must be available in the unseen dataset.\n",
    "\n",
    "probability_threshold: float, default = None\n",
    "Threshold for converting predicted probability to class label. Unless this parameter is set, it will default to the value set during model creation. If that wasn’t set, the default will be 0.5 for all classifiers. Only applicable for binary classification.\n",
    "\n",
    "encoded_labels: bool, default = False\n",
    "When set to True, will return labels encoded as an integer.\n",
    "\n",
    "raw_score: bool, default = False\n",
    "When set to True, scores for all labels will be returned.\n",
    "\n",
    "drift_report: bool, default = False\n",
    "When set to True, interactive drift report is generated on test set with the evidently library.\n",
    "\n",
    "round: int, default = 4\n",
    "Number of decimal places the metrics in the score grid will be rounded to.\n",
    "\n",
    "verbose: bool, default = True\n",
    "When set to False, holdout score grid is not printed.\n",
    "\n",
    "Returns\n",
    "pandas.DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**classification finalize_model function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function trains a given estimator on the entire dataset including the holdout set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.datasets import get_data\n",
    "juice = get_data('juice')\n",
    "from pycaret.classification import *\n",
    "exp_name = setup(data = juice,  target = 'Purchase')\n",
    "lr = create_model('lr')\n",
    "final_lr = finalize_model(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycaret.classification.finalize_model(estimator, \n",
    "                                      fit_kwargs: Optional[dict] = None, \n",
    "                                      groups: Optional[Union[str, Any]] = None, \n",
    "                                      model_only: bool = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estimator: scikit-learn compatible object\n",
    "Trained model object\n",
    "\n",
    "fit_kwargs: dict, default = {} (empty dict)\n",
    "Dictionary of arguments passed to the fit method of the model.\n",
    "\n",
    "groups: str or array-like, with shape (n_samples,), default = None\n",
    "Optional group labels when GroupKFold is used for the cross validation. It takes an array with shape (n_samples, ) where n_samples is the number of rows in training dataset. When string is passed, it is interpreted as the column name in the dataset containing group labels.\n",
    "\n",
    "model_only: bool, default = True\n",
    "When set to False, only model object is re-trained and all the transformations in Pipeline are ignored.\n",
    "\n",
    "Returns\n",
    "Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**classification deploy_model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function deploys the transformation pipeline and trained model on cloud.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.datasets import get_data\n",
    "juice = get_data('juice')\n",
    "from pycaret.classification import *\n",
    "exp_name = setup(data = juice,  target = 'Purchase')\n",
    "lr = create_model('lr')\n",
    "# sets appropriate credentials for the platform as environment variables\n",
    "import os\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = str(\"foo\")\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = str(\"bar\")\n",
    "deploy_model(model = lr, model_name = 'lr-for-deployment', platform = 'aws', authentication = {'bucket' : 'S3-bucket-name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycaret.classification.deploy_model(model, \n",
    "                                    model_name: str, \n",
    "                                    authentication: dict, \n",
    "                                    platform: str = 'aws')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon Web Service (AWS) users:\n",
    "To deploy a model on AWS S3 (‘aws’), the credentials have to be passed. The easiest way is to use environment variables in your local environment. Following information from the IAM portal of amazon console account are required:\n",
    "\n",
    "AWS Access Key ID\n",
    "\n",
    "AWS Secret Key Access\n",
    "\n",
    "More info: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html#environment-variables\n",
    "\n",
    "Google Cloud Platform (GCP) users:\n",
    "To deploy a model on Google Cloud Platform (‘gcp’), project must be created using command line or GCP console. Once project is created, you must create a service account and download the service account key as a JSON file to set environment variables in your local environment.\n",
    "\n",
    "More info: https://cloud.google.com/docs/authentication/production\n",
    "\n",
    "Microsoft Azure (Azure) users:\n",
    "To deploy a model on Microsoft Azure (‘azure’), environment variables for connection string must be set in your local environment. Go to settings of storage account on Azure portal to access the connection string required.\n",
    "\n",
    "AZURE_STORAGE_CONNECTION_STRING (required as environment variable)\n",
    "\n",
    "More info: https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-python?toc=%2Fpython%2Fazure%2FTOC.json\n",
    "\n",
    "model: scikit-learn compatible object\n",
    "Trained model object\n",
    "\n",
    "model_name: str\n",
    "Name of model.\n",
    "\n",
    "authentication: dict\n",
    "Dictionary of applicable authentication tokens.\n",
    "\n",
    "When platform = ‘aws’: {‘bucket’ : ‘S3-bucket-name’, ‘path’: (optional) folder name under the bucket}\n",
    "\n",
    "When platform = ‘gcp’: {‘project’: ‘gcp-project-name’, ‘bucket’ : ‘gcp-bucket-name’}\n",
    "\n",
    "When platform = ‘azure’: {‘container’: ‘azure-container-name’}\n",
    "\n",
    "platform: str, default = ‘aws’\n",
    "Name of the platform. Currently supported platforms: ‘aws’, ‘gcp’ and ‘azure’.\n",
    "\n",
    "Returns\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**classification save_model function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function saves the transformation pipeline and trained model object into the current working directory as a pickle file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.datasets import get_data\n",
    "juice = get_data('juice')\n",
    "from pycaret.classification import *\n",
    "exp_name = setup(data = juice,  target = 'Purchase')\n",
    "lr = create_model('lr')\n",
    "save_model(lr, 'saved_lr_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycaret.classification.save_model(model, model_name: str, \n",
    "                                  model_only: bool = False, \n",
    "                                  verbose: bool = True, \n",
    "                                  **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model: scikit-learn compatible object\n",
    "Trained model object\n",
    "\n",
    "model_name: str\n",
    "Name of the model.\n",
    "\n",
    "model_only: bool, default = False\n",
    "When set to True, only trained model object is saved instead of the entire pipeline.\n",
    "\n",
    "verbose: bool, default = True\n",
    "Success message is not printed when verbose is set to False.\n",
    "\n",
    "**kwargs:\n",
    "Additional keyword arguments to pass to joblib.dump().\n",
    "\n",
    "Returns\n",
    "Tuple of the model object and the filename."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**clasiffication load_model function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function loads a previously saved pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import load_model\n",
    "saved_lr = load_model('saved_lr_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycaret.classification.load_model(model_name, \n",
    "                                  platform: Optional[str] = None, \n",
    "                                  authentication: Optional[Dict[str, str]] = None, \n",
    "                                  verbose: bool = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_name: str\n",
    "Name of the model.\n",
    "\n",
    "platform: str, default = None\n",
    "Name of the cloud platform. Currently supported platforms: ‘aws’, ‘gcp’ and ‘azure’.\n",
    "\n",
    "authentication: dict, default = None\n",
    "dictionary of applicable authentication tokens.\n",
    "\n",
    "when platform = ‘aws’: {‘bucket’ : ‘S3-bucket-name’}\n",
    "\n",
    "when platform = ‘gcp’: {‘project’: ‘gcp-project-name’, ‘bucket’ : ‘gcp-bucket-name’}\n",
    "\n",
    "when platform = ‘azure’: {‘container’: ‘azure-container-name’}\n",
    "\n",
    "verbose: bool, default = True\n",
    "Success message is not printed when verbose is set to False.\n",
    "\n",
    "Returns\n",
    "Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**classification automl function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns the best model out of all trained models in current session based on the optimize parameter. Metrics evaluated can be accessed using the get_metrics function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycaret.classification.automl(optimize: str = 'Accuracy', \n",
    "                              use_holdout: bool = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.datasets import get_data\n",
    "juice = get_data('juice')\n",
    "from pycaret.classification import *\n",
    "exp_name = setup(data = juice,  target = 'Purchase')\n",
    "top3 = compare_models(n_select = 3)\n",
    "tuned_top3 = [tune_model(i) for i in top3]\n",
    "blender = blend_models(tuned_top3)\n",
    "stacker = stack_models(tuned_top3)\n",
    "best_auc_model = automl(optimize = 'AUC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimize: str, default = ‘Accuracy’\n",
    "Metric to use for model selection. It also accepts custom metrics added using the add_metric function.\n",
    "\n",
    "use_holdout: bool, default = False\n",
    "When set to True, metrics are evaluated on holdout set instead of CV.\n",
    "\n",
    "Returns\n",
    "Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**classification pull function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns last printed score grid. Use pull function after any training function to store the score grid in pandas.DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycaret.classification.pull(pop: bool = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Returns last printed score grid. Use pull function after any training function to store the score grid in pandas.DataFrame.\n",
    "\n",
    "pop: bool, default = False\n",
    "If True, will pop (remove) the returned dataframe from the display container.\n",
    "\n",
    "Returns\n",
    "pandas.DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**classification models function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns table of models available in the model library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.datasets import get_data\n",
    "juice = get_data('juice')\n",
    "from pycaret.classification import *\n",
    "exp_name = setup(data = juice,  target = 'Purchase')\n",
    "all_models = models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycaret.classification.models(type: Optional[str] = None, \n",
    "                              internal: bool = False, \n",
    "                              raise_errors: bool = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "type: str, default = None\n",
    "linear : filters and only return linear models\n",
    "\n",
    "tree : filters and only return tree based models\n",
    "\n",
    "ensemble : filters and only return ensemble models\n",
    "\n",
    "internal: bool, default = False\n",
    "When True, will return extra columns and rows used internally.\n",
    "\n",
    "raise_errors: bool, default = True\n",
    "When False, will suppress all exceptions, ignoring models that couldn’t be created.\n",
    "\n",
    "Returns\n",
    "pandas.DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**classification get_metrics function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns table of available metrics used for CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.datasets import get_data\n",
    "juice = get_data('juice')\n",
    "from pycaret.classification import *\n",
    "exp_name = setup(data = juice,  target = 'Purchase')\n",
    "all_metrics = get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycaret.classification.get_metrics(reset: bool = False, include_custom: bool = True, raise_errors: bool = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reset: bool, default = False\n",
    "When True, will reset all changes made using the add_metric and remove_metric function.\n",
    "\n",
    "include_custom: bool, default = True\n",
    "Whether to include user added (custom) metrics or not.\n",
    "\n",
    "raise_errors: bool, default = True\n",
    "If False, will suppress all exceptions, ignoring models that couldn’t be created.\n",
    "\n",
    "Returns\n",
    "pandas.DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**classification add_metric function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adds a custom metric to be used for CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.datasets import get_data\n",
    "juice = get_data('juice')\n",
    "from pycaret.classification import *\n",
    "exp_name = setup(data = juice,  target = 'Purchase')\n",
    "from sklearn.metrics import log_loss\n",
    "add_metric('logloss', 'Log Loss', log_loss, greater_is_better = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycaret.classification.add_metric(id: str, name: str, \n",
    "                                  score_func: type, \n",
    "                                  target: str = 'pred', \n",
    "                                  greater_is_better: bool = True, \n",
    "                                  multiclass: bool = True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "id: str\n",
    "Unique id for the metric.\n",
    "\n",
    "name: str\n",
    "Display name of the metric.\n",
    "\n",
    "score_func: type\n",
    "Score function (or loss function) with signature score_func(y, y_pred, **kwargs).\n",
    "\n",
    "target: str, default = ‘pred’\n",
    "The target of the score function.\n",
    "\n",
    "‘pred’ for the prediction table\n",
    "\n",
    "‘pred_proba’ for pred_proba\n",
    "\n",
    "‘threshold’ for decision_function or predict_proba\n",
    "\n",
    "greater_is_better: bool, default = True\n",
    "Whether score_func is higher the better or not.\n",
    "\n",
    "multiclass: bool, default = True\n",
    "Whether the metric supports multiclass target.\n",
    "\n",
    "**kwargs:\n",
    "Arguments to be passed to score function.\n",
    "\n",
    "Returns\n",
    "pandas.Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**classification remove_metric function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removes a metric from CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.datasets import get_data\n",
    "juice = get_data('juice')\n",
    "from pycaret.classification import *\n",
    "exp_name = setup(data = juice,  target = 'Purchase')\n",
    "remove_metric('MCC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycaret.classification.remove_metric(name_or_id: str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "name_or_id: str\n",
    "Display name or ID of the metric.\n",
    "\n",
    "Returns\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycaret.classification.get_logs(experiment_name: Optional[str] = None, save: bool = False)→ pandas.core.frame.DataFramev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
